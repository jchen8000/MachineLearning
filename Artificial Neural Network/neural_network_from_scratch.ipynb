{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MwVkDk443U9"
      },
      "source": [
        "# Artificial Neural Network\n",
        "\n",
        "***ABSTRACT***\n",
        "\n",
        "***In this hands-on practice we build a self-defined Neural Network from scratch by defining the parameters $\\Theta$, the sigmoid function, derivative of sigmoid, cross-entropy  function, and performing all the calculations for Forward Propagation and Backpropagtion to train the neural network. We also collect the cost history and accuracy score during the calculation and finally plot the cost diagram and accuracy diagram to show how the process is going. We use the Churn_Modelling Dataset for the training of our neural network, which is consist of 10,000 bank customer data, we build this Neural Network model to predict whether a customer will left or remain in the bank. Finally we received the accuracy score of 0.84.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cG6XbGfF6mqc"
      },
      "source": [
        "## 1. Churn_Modelling Dataset\n",
        "\n",
        "The Churn Modelling dataset contains customers information of a bank with a flag that s/he exits from the bank within 6 months. We will build an ANN to learn from the dataset and predict if a customer will leave the bank or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nk0zkAdMG0vZ"
      },
      "source": [
        "### 1.1 Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d13XAkG76vho",
        "outputId": "7abe4f08-d61a-42b9-c7d2-7b03b0bb0f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "datafile = 'https://floobits.com/calvinlow18/ANN/raw/Churn_Modelling.csv'\n",
        "dataset = pd.read_csv(datafile)\n",
        "dataset.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "3          4    15701354      Boni  ...               0        93826.63      0\n",
              "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98O3WxVX7x3M",
        "colab": {}
      },
      "source": [
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "\n",
        "#y shape looks like (m,), make it looks like (m,1)\n",
        "y = y[:,np.newaxis]    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jc5Qt_WtG-tQ"
      },
      "source": [
        "### 1.2 Encoding categorical data and Feature Scaling\n",
        "\n",
        "Encode the country name (string)  and female/male (string) as One Hot Encoding.\n",
        "Standard scaler other numeric data\n",
        "\n",
        "Also need One Hot Encoding, see [Label Encoder vs. One Hot Encoder](https://medium.com/@contactsunny/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXyBqQElpgCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "preprocess = make_column_transformer(\n",
        "    (OneHotEncoder(),[1,2]),\n",
        "    (StandardScaler(),[0,3,4,5,6,7,8,9])\n",
        "    #(MinMaxScaler(feature_range=(0, 1)),[0,3,4,5,6,7,8,9])\n",
        ")\n",
        "\n",
        "X = preprocess.fit_transform(X)\n",
        "\n",
        "m = X.shape[0]\n",
        "X = np.hstack((np.ones((m,1)), X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_V7uylCl43VT"
      },
      "source": [
        "### 1.3 Splitting the dataset into the Training set and Test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZC-jcbxGDsg0",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vH7w4qLR43Vs",
        "outputId": "566548ee-d2b0-4510-8c4e-9b534f750fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print( X_train.shape )\n",
        "print( X_test.shape )\n",
        "print( y_train.shape )\n",
        "print( y_test.shape )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 14)\n",
            "(2000, 14)\n",
            "(8000, 1)\n",
            "(2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFQoOEm5O6Df"
      },
      "source": [
        "## 2. Build a Neural Network from scratch\n",
        "\n",
        "![Neural Network Model](https://raw.githubusercontent.com/jchen8000/MachineLearning/master/images/NeuralNetwork.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyhY0YbXFH0A",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Cross-Entropy Cost Function\n",
        "\n",
        "> ## $ \\min_\\Theta J(\\Theta)=-\\frac{\\mathrm{1} }{m} \\sum_{i=1}^{m}  \\sum_{k=1}^{K}\\left[ y_k^{(i)} log((h_\\Theta(x^{(i)}))_k) + (1 - y_k^{(i)}) log (1 - (h_\\Theta(x^{(i)}))_k) \\right]  + \\frac{\\mathrm{\\lambda}}{2m}  \\sum_{l=1}^{L-1} \\sum_{i=1}^{S_l}\\sum_{j=1}^{S_l+1}( \\Theta_{ji}^{(l)})^2$\n",
        "\n",
        "> Where $ h_\\Theta(x)  \\in  \\mathbb{R}^K, (h_\\Theta(x))_i = i^{th} output  $\n",
        "\n",
        "> $ L = $ total no. of layers in neural network\n",
        "\n",
        "> $ S_l = $ no. of units (not couning bias unit ) in layer $ l $\n",
        "\n",
        "> ### Think of $ J(\\Theta) \\approx ( h_\\Theta(x^{(i)}) - y^{(i)} ) ^2 $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bk-Na74oPVeu"
      },
      "source": [
        "### 2.2 Sigmoid Function and Derivative of Sigmoid\n",
        "\n",
        "*  **Sigmoid Function:**\n",
        "> ## $ g(z) = sigmoid(z) = \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-z} }  $\n",
        "\n",
        "\n",
        "*  **Derivative of Sigmoid Function:**\n",
        "> ## $\\frac{\\mathrm{d} }{\\mathrm{d} z}g(z) = g(z)(1-g(z)) $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6ATuXdxt43Wd"
      },
      "source": [
        "### 2.3 Backpropagation\n",
        "\n",
        "> ## $  \\delta^{(3)}_j = a_j^{(3)} - y_j $,  ( total number of layers $ L = 3 $ )\n",
        "\n",
        "> ## $  \\delta^{(2)} = ( \\Theta^{(2)} )^T  \\delta^{(3)} .* g'(z^{(2)}) $\n",
        "\n",
        "> ## $  \\delta^{(1)} = ( \\Theta^{(1)} )^T  \\delta^{(2)} .* g'(z^{(1)}) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N1Re9DpR1Qk_",
        "colab": {}
      },
      "source": [
        "class Neural_Network(object):\n",
        "  def __init__(self, inputSize, hiddenSize, outputSize, lmbda):\n",
        "  #parameters\n",
        "    self.inputSize = inputSize\n",
        "    self.outputSize = outputSize\n",
        "    self.hiddenSize = hiddenSize\n",
        "    self.lmbda = lmbda\n",
        "    \n",
        "  #weights\n",
        "    epsilon = 0.2\n",
        "    np.random.seed(3)\n",
        "    self.theta1 = np.random.randn(self.inputSize, self.hiddenSize)  * 2 * epsilon - epsilon\n",
        "    self.theta2 = np.random.randn(self.hiddenSize, self.outputSize) * 2 * epsilon - epsilon\n",
        "    #self.theta1 = np.random.rand(self.inputSize, self.hiddenSize) * 2 * epsilon - epsilon\n",
        "    #self.theta2 = np.random.rand(self.hiddenSize, self.outputSize) * 2 * epsilon - epsilon\n",
        "    \n",
        "  #history\n",
        "    self.loss_history =  [] \n",
        "    self.cost_history =  [] \n",
        "    self.accuracy_history = []\n",
        "\n",
        "  def forward(self, X):\n",
        "    #forward propagation through our network\n",
        "    \n",
        "    #Go from input to hidden layer, apply Sigmoid activation function\n",
        "    self.z = X @ self.theta1 \n",
        "    self.z2 = self.sigmoid(self.z) \n",
        "    \n",
        "    #Go from hidden layer to output, apply Sigmoid activation function\n",
        "    self.z3 = self.z2 @ self.theta2 \n",
        "    output = self.sigmoid(self.z3) \n",
        "    \n",
        "    return output\n",
        "\n",
        "  def sigmoid(self, s):\n",
        "    # Sigmoid activation function\n",
        "    return 1/(1+np.exp(-s))\n",
        "\n",
        "  def sigmoidDerivative(self, s):\n",
        "    #derivative of Sigmoid\n",
        "    return s * (1 - s)\n",
        "\n",
        "  def backward(self, X, y, output):\n",
        "    # backward propagate through the network\n",
        "    \n",
        "    #delta of output layer: calculate output error, and apply derivative of Sigmoid to it\n",
        "    self.o_error = y - output \n",
        "    self.o_delta = self.o_error * self.sigmoidDerivative(output) \n",
        "    \n",
        "    #calculate delta of hidden layer: calculate hidden layer error, and apply derivative of Sigmoid to it\n",
        "    self.z2_error = self.o_delta @ self.theta2.T\n",
        "    self.z2_delta = self.z2_error * self.sigmoidDerivative(self.z2) \n",
        "\n",
        "    #Update theta1 and theta2\n",
        "    self.theta1 += X.T @ self.z2_delta \n",
        "    self.theta2 += self.z2.T @ self.o_delta \n",
        " \n",
        "\n",
        "  def cost(self, X, y ):\n",
        "    m = len(y)\n",
        "    y_output = self.forward(X)\n",
        "    \n",
        "    #calculate based on Cross-Entropy formula\n",
        "    c1 = y * np.log(y_output)\n",
        "    c2 = (1-y) * np.log(1-y_output)\n",
        "    c = np.sum(c1 + c2)\n",
        "    \n",
        "    #add regulation factors\n",
        "    r1 = np.sum(np.sum(np.power(self.theta1,2), axis = 1))\n",
        "    r2 = np.sum(np.sum(np.power(self.theta2,2), axis = 1))\n",
        "    \n",
        "    return np.sum(c / (-m)) + ((r1 + r2) * self.lmbda) / (2*m)\n",
        "\n",
        "  \n",
        "  def loss(self, X, y):\n",
        "    return (np.square(y - self.forward(X))).mean(axis=None)\n",
        "\n",
        "  \n",
        "  def train(self, X, y, epoch):\n",
        "    for i in range(epoch):\n",
        "      output = self.forward(X)\n",
        "      self.backward(X, y, output )\n",
        "      acry = accuracy_score(y, (output >= 0.5) )\n",
        "      cost = self.cost(X, y)\n",
        "      loss = self.loss(X, y)\n",
        "      self.loss_history.append(loss)\n",
        "      self.cost_history.append(cost)\n",
        "      self.accuracy_history.append(acry)\n",
        "      print(\"epoch:[\", i, \"], cost:\", str(cost), \"; loss:\", str(loss) + \"; accuracy:\", str(acry)  )\n",
        "\n",
        "  def predict(self, X):\n",
        "    return self.forward(X)\n",
        "  \n",
        "  \n",
        "  def get_cost_histroy(self):\n",
        "    return self.cost_history\n",
        "  \n",
        "  def get_loss_histroy(self):\n",
        "    return self.loss_history\n",
        "\n",
        "  def get_accuracy_histroy(self):\n",
        "    return self.accuracy_history  \n",
        "  \n",
        "  def get_weight(self):\n",
        "    return self.theta1, self.theta2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1MjhrdvPyAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotCost(cost_history, epoch):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(range(len(cost_history)),cost_history,'bo')\n",
        "    plt.grid(True)\n",
        "    plt.title(\"Cost by epoch\")\n",
        "    plt.xlabel(\"Iteration number\")\n",
        "    plt.ylabel(\"Cost\")\n",
        "    dummy = plt.xlim([-0.05*epoch,1.05*epoch])\n",
        "    dummy = plt.ylim([min(cost_history)-0.2*(max(cost_history)-min(cost_history)), max(cost_history)+0.2*(max(cost_history)-min(cost_history))])\n",
        "\n",
        "    \n",
        "def plotAccuracy(accuracy_history, epoch):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(range(len(accuracy_history)),accuracy_history,'r.')\n",
        "    plt.grid(True)\n",
        "    plt.title(\"Accuracy by epoch\")\n",
        "    plt.xlabel(\"Iteration number\")\n",
        "    plt.ylabel(\"Accuracy Score\")\n",
        "    dummy = plt.xlim([-0.05*epoch,1.05*epoch])\n",
        "    dummy = plt.ylim([min(accuracy_history)-0.2*(max(accuracy_history)-min(accuracy_history)), max(accuracy_history)+0.2*(max(accuracy_history)-min(accuracy_history))])\n",
        "  \n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4suFNvfWj2A",
        "colab_type": "code",
        "outputId": "870ccb4e-ae69-4d1f-dc94-b936ac0cd721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17017
        }
      },
      "source": [
        "NN = Neural_Network( inputSize=14, \n",
        "                     hiddenSize=3, \n",
        "                     outputSize=1, \n",
        "                     lmbda=0.5 )\n",
        "\n",
        "\n",
        "epoch = 1000\n",
        "NN.train(X_train, y_train, epoch)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:[ 0 ], cost: 33.235267636400664 ; loss: 0.19252586210041667; accuracy: 0.796\n",
            "epoch:[ 1 ], cost: 30.170349162499235 ; loss: 0.18498910824815842; accuracy: 0.795875\n",
            "epoch:[ 2 ], cost: 27.92490790464698 ; loss: 0.18082398717443926; accuracy: 0.796375\n",
            "epoch:[ 3 ], cost: 26.18838305136901 ; loss: 0.17602994509910275; accuracy: 0.797\n",
            "epoch:[ 4 ], cost: 24.324074623028395 ; loss: 0.17189526482471795; accuracy: 0.7965\n",
            "epoch:[ 5 ], cost: 24.30445006915238 ; loss: 0.1682462667397825; accuracy: 0.799875\n",
            "epoch:[ 6 ], cost: 23.292692283503992 ; loss: 0.16551986638812805; accuracy: 0.797875\n",
            "epoch:[ 7 ], cost: 21.556269056695974 ; loss: 0.1623871290126739; accuracy: 0.798625\n",
            "epoch:[ 8 ], cost: 21.763389797181286 ; loss: 0.16027442453453816; accuracy: 0.803125\n",
            "epoch:[ 9 ], cost: 20.920196579972618 ; loss: 0.15985892771894117; accuracy: 0.802875\n",
            "epoch:[ 10 ], cost: 21.031616044205855 ; loss: 0.1591306732826504; accuracy: 0.80325\n",
            "epoch:[ 11 ], cost: 20.59370433779656 ; loss: 0.15855489767758252; accuracy: 0.802875\n",
            "epoch:[ 12 ], cost: 20.49667382906124 ; loss: 0.15768755608327878; accuracy: 0.804875\n",
            "epoch:[ 13 ], cost: 20.09121776825237 ; loss: 0.15757056301122088; accuracy: 0.80425\n",
            "epoch:[ 14 ], cost: 20.375981963074253 ; loss: 0.15800862565846122; accuracy: 0.803125\n",
            "epoch:[ 15 ], cost: 19.199987596571592 ; loss: 0.15779853166829455; accuracy: 0.80375\n",
            "epoch:[ 16 ], cost: 19.40160132061163 ; loss: 0.1569074318435878; accuracy: 0.805625\n",
            "epoch:[ 17 ], cost: 19.80079821802089 ; loss: 0.1567536119317028; accuracy: 0.806375\n",
            "epoch:[ 18 ], cost: 18.637219687472427 ; loss: 0.15656505036784915; accuracy: 0.8035\n",
            "epoch:[ 19 ], cost: 18.62143541321773 ; loss: 0.15628297635216581; accuracy: 0.809125\n",
            "epoch:[ 20 ], cost: 18.43699418484582 ; loss: 0.15573892935668437; accuracy: 0.806875\n",
            "epoch:[ 21 ], cost: 18.490925044513084 ; loss: 0.15528909506229502; accuracy: 0.809625\n",
            "epoch:[ 22 ], cost: 18.19046159324405 ; loss: 0.15499446802277392; accuracy: 0.809375\n",
            "epoch:[ 23 ], cost: 18.31838956657423 ; loss: 0.15465825804785782; accuracy: 0.81025\n",
            "epoch:[ 24 ], cost: 17.92718933821527 ; loss: 0.15418615775400416; accuracy: 0.808875\n",
            "epoch:[ 25 ], cost: 18.052613329160483 ; loss: 0.15390721719389078; accuracy: 0.8105\n",
            "epoch:[ 26 ], cost: 17.94503754842533 ; loss: 0.15399214343975567; accuracy: 0.81025\n",
            "epoch:[ 27 ], cost: 17.763280387177655 ; loss: 0.15355465555859082; accuracy: 0.80925\n",
            "epoch:[ 28 ], cost: 17.47454358957437 ; loss: 0.15328070947015487; accuracy: 0.810875\n",
            "epoch:[ 29 ], cost: 17.87131575391244 ; loss: 0.15435716980472677; accuracy: 0.81175\n",
            "epoch:[ 30 ], cost: 16.815945508052597 ; loss: 0.1531344241274117; accuracy: 0.8095\n",
            "epoch:[ 31 ], cost: 17.11656604237783 ; loss: 0.15262462938409818; accuracy: 0.8125\n",
            "epoch:[ 32 ], cost: 16.61473566103555 ; loss: 0.15245677365212595; accuracy: 0.8105\n",
            "epoch:[ 33 ], cost: 17.12231119505796 ; loss: 0.15268488131400745; accuracy: 0.8135\n",
            "epoch:[ 34 ], cost: 16.23950498970096 ; loss: 0.15188258731912552; accuracy: 0.80925\n",
            "epoch:[ 35 ], cost: 16.553117494349266 ; loss: 0.15139834637366112; accuracy: 0.812875\n",
            "epoch:[ 36 ], cost: 15.805137674779097 ; loss: 0.1514867624514478; accuracy: 0.80975\n",
            "epoch:[ 37 ], cost: 15.817875063048563 ; loss: 0.1514028273529068; accuracy: 0.81325\n",
            "epoch:[ 38 ], cost: 16.292005935165406 ; loss: 0.15127920129860123; accuracy: 0.8125\n",
            "epoch:[ 39 ], cost: 15.23336926619455 ; loss: 0.15183133877826713; accuracy: 0.81025\n",
            "epoch:[ 40 ], cost: 15.270799631981637 ; loss: 0.15097967720876326; accuracy: 0.813875\n",
            "epoch:[ 41 ], cost: 15.453288061626475 ; loss: 0.15024761520607682; accuracy: 0.815125\n",
            "epoch:[ 42 ], cost: 15.32248158773122 ; loss: 0.15031486547232872; accuracy: 0.814\n",
            "epoch:[ 43 ], cost: 15.275518194711823 ; loss: 0.15148479448622795; accuracy: 0.813875\n",
            "epoch:[ 44 ], cost: 15.018432579025701 ; loss: 0.14969063573481411; accuracy: 0.812875\n",
            "epoch:[ 45 ], cost: 15.29688814580667 ; loss: 0.14967842029295048; accuracy: 0.8135\n",
            "epoch:[ 46 ], cost: 14.74155098536621 ; loss: 0.14951662314402528; accuracy: 0.811625\n",
            "epoch:[ 47 ], cost: 14.807382376781922 ; loss: 0.1489475608180823; accuracy: 0.814125\n",
            "epoch:[ 48 ], cost: 14.825108046952774 ; loss: 0.14878339583010172; accuracy: 0.812875\n",
            "epoch:[ 49 ], cost: 14.931519805443218 ; loss: 0.1498153128512112; accuracy: 0.81325\n",
            "epoch:[ 50 ], cost: 13.983196218288727 ; loss: 0.1494732452834329; accuracy: 0.812875\n",
            "epoch:[ 51 ], cost: 14.483135141673685 ; loss: 0.14805193213901988; accuracy: 0.8145\n",
            "epoch:[ 52 ], cost: 14.659217103676777 ; loss: 0.1489627074030878; accuracy: 0.813125\n",
            "epoch:[ 53 ], cost: 13.953381190588516 ; loss: 0.1482605855838062; accuracy: 0.81225\n",
            "epoch:[ 54 ], cost: 14.375526887378644 ; loss: 0.14862920095741441; accuracy: 0.8145\n",
            "epoch:[ 55 ], cost: 13.525557140181071 ; loss: 0.14877817898175608; accuracy: 0.812\n",
            "epoch:[ 56 ], cost: 13.577888732037675 ; loss: 0.14775030799252614; accuracy: 0.817125\n",
            "epoch:[ 57 ], cost: 13.764565340079292 ; loss: 0.1474513676750135; accuracy: 0.81575\n",
            "epoch:[ 58 ], cost: 13.376476223703705 ; loss: 0.1476641872076299; accuracy: 0.81525\n",
            "epoch:[ 59 ], cost: 13.866670656601471 ; loss: 0.14768807207758103; accuracy: 0.81675\n",
            "epoch:[ 60 ], cost: 13.335598636593584 ; loss: 0.14762797121049806; accuracy: 0.815125\n",
            "epoch:[ 61 ], cost: 13.638541597006789 ; loss: 0.14726202665690455; accuracy: 0.815875\n",
            "epoch:[ 62 ], cost: 12.788524970150384 ; loss: 0.14797589936476507; accuracy: 0.815875\n",
            "epoch:[ 63 ], cost: 12.978441391424175 ; loss: 0.14745037152728388; accuracy: 0.817625\n",
            "epoch:[ 64 ], cost: 13.263286976539648 ; loss: 0.14746576443832074; accuracy: 0.818125\n",
            "epoch:[ 65 ], cost: 13.079529425943813 ; loss: 0.14691372922705942; accuracy: 0.8165\n",
            "epoch:[ 66 ], cost: 13.1216433251984 ; loss: 0.14715528082823426; accuracy: 0.817875\n",
            "epoch:[ 67 ], cost: 13.160315903378741 ; loss: 0.14684513586804007; accuracy: 0.817\n",
            "epoch:[ 68 ], cost: 12.82170725104196 ; loss: 0.14691138744083684; accuracy: 0.817125\n",
            "epoch:[ 69 ], cost: 13.282369257650595 ; loss: 0.14739232975901; accuracy: 0.81775\n",
            "epoch:[ 70 ], cost: 12.775869950948643 ; loss: 0.14747646350731983; accuracy: 0.8165\n",
            "epoch:[ 71 ], cost: 12.87835888879035 ; loss: 0.14700283364917496; accuracy: 0.816375\n",
            "epoch:[ 72 ], cost: 13.202565854753086 ; loss: 0.14686518190412876; accuracy: 0.8185\n",
            "epoch:[ 73 ], cost: 13.039008081094128 ; loss: 0.1466749417333163; accuracy: 0.815625\n",
            "epoch:[ 74 ], cost: 12.998412901133356 ; loss: 0.1465054500407421; accuracy: 0.816625\n",
            "epoch:[ 75 ], cost: 12.739935330809502 ; loss: 0.14662101826144652; accuracy: 0.81725\n",
            "epoch:[ 76 ], cost: 13.22671125218056 ; loss: 0.14704318453723592; accuracy: 0.817625\n",
            "epoch:[ 77 ], cost: 12.601938341186568 ; loss: 0.14692982688286924; accuracy: 0.816\n",
            "epoch:[ 78 ], cost: 12.787029474976586 ; loss: 0.14688172599689234; accuracy: 0.818625\n",
            "epoch:[ 79 ], cost: 12.909687257559403 ; loss: 0.14619807449621958; accuracy: 0.818125\n",
            "epoch:[ 80 ], cost: 12.876321876838642 ; loss: 0.14602117669414041; accuracy: 0.816625\n",
            "epoch:[ 81 ], cost: 12.968691051222127 ; loss: 0.14604239949669973; accuracy: 0.81725\n",
            "epoch:[ 82 ], cost: 12.47932820973246 ; loss: 0.1464031457300598; accuracy: 0.816375\n",
            "epoch:[ 83 ], cost: 12.624811784286068 ; loss: 0.14582509762927498; accuracy: 0.81875\n",
            "epoch:[ 84 ], cost: 13.011009221286226 ; loss: 0.14630357227849658; accuracy: 0.817875\n",
            "epoch:[ 85 ], cost: 12.345249546742394 ; loss: 0.1467396133738662; accuracy: 0.8165\n",
            "epoch:[ 86 ], cost: 12.892802344441057 ; loss: 0.1461657976447202; accuracy: 0.820875\n",
            "epoch:[ 87 ], cost: 12.254746471422507 ; loss: 0.14680719483048985; accuracy: 0.817125\n",
            "epoch:[ 88 ], cost: 12.657485660431867 ; loss: 0.145828547913312; accuracy: 0.8215\n",
            "epoch:[ 89 ], cost: 12.328382401381651 ; loss: 0.14616051732211804; accuracy: 0.819125\n",
            "epoch:[ 90 ], cost: 12.943249938465728 ; loss: 0.14634871314346878; accuracy: 0.82125\n",
            "epoch:[ 91 ], cost: 12.070984399333067 ; loss: 0.14642633024150978; accuracy: 0.817375\n",
            "epoch:[ 92 ], cost: 12.073642803094437 ; loss: 0.14608751388554903; accuracy: 0.82175\n",
            "epoch:[ 93 ], cost: 11.80792924591809 ; loss: 0.14691531948787492; accuracy: 0.820875\n",
            "epoch:[ 94 ], cost: 12.218521215227973 ; loss: 0.14554299684626051; accuracy: 0.82175\n",
            "epoch:[ 95 ], cost: 12.135220618862292 ; loss: 0.14532441821840666; accuracy: 0.81875\n",
            "epoch:[ 96 ], cost: 12.011468298208962 ; loss: 0.1449468574113176; accuracy: 0.81875\n",
            "epoch:[ 97 ], cost: 11.93031157464128 ; loss: 0.1449695776555971; accuracy: 0.82\n",
            "epoch:[ 98 ], cost: 11.823787888937694 ; loss: 0.14481050853819852; accuracy: 0.81975\n",
            "epoch:[ 99 ], cost: 12.106066070203251 ; loss: 0.14594806285797454; accuracy: 0.820625\n",
            "epoch:[ 100 ], cost: 11.626293164350475 ; loss: 0.14694967450111746; accuracy: 0.818375\n",
            "epoch:[ 101 ], cost: 11.90466856147551 ; loss: 0.14576311668415748; accuracy: 0.81925\n",
            "epoch:[ 102 ], cost: 12.061264678148357 ; loss: 0.14521835391552837; accuracy: 0.81975\n",
            "epoch:[ 103 ], cost: 11.284487455729918 ; loss: 0.14650626818517198; accuracy: 0.818625\n",
            "epoch:[ 104 ], cost: 11.67826447336087 ; loss: 0.14598191883107622; accuracy: 0.822125\n",
            "epoch:[ 105 ], cost: 11.446089527093438 ; loss: 0.14574156300983407; accuracy: 0.821125\n",
            "epoch:[ 106 ], cost: 11.874541679603432 ; loss: 0.14488281749582302; accuracy: 0.82175\n",
            "epoch:[ 107 ], cost: 11.663912870561395 ; loss: 0.14482428166441005; accuracy: 0.8195\n",
            "epoch:[ 108 ], cost: 11.841747159029833 ; loss: 0.14601638468306402; accuracy: 0.820375\n",
            "epoch:[ 109 ], cost: 11.744992827850448 ; loss: 0.1449679555555462; accuracy: 0.819375\n",
            "epoch:[ 110 ], cost: 11.800123530015014 ; loss: 0.14671019568238391; accuracy: 0.81875\n",
            "epoch:[ 111 ], cost: 11.243134990780035 ; loss: 0.1460184726697329; accuracy: 0.81925\n",
            "epoch:[ 112 ], cost: 11.945254946149873 ; loss: 0.14511258160769397; accuracy: 0.82175\n",
            "epoch:[ 113 ], cost: 11.41207714781159 ; loss: 0.14539159207331004; accuracy: 0.818375\n",
            "epoch:[ 114 ], cost: 11.758529668172562 ; loss: 0.14443470980185097; accuracy: 0.8205\n",
            "epoch:[ 115 ], cost: 12.047274099843673 ; loss: 0.14548335799997078; accuracy: 0.819375\n",
            "epoch:[ 116 ], cost: 11.13290150097188 ; loss: 0.14650954653779616; accuracy: 0.817875\n",
            "epoch:[ 117 ], cost: 11.806783454878364 ; loss: 0.14475839434834387; accuracy: 0.82125\n",
            "epoch:[ 118 ], cost: 11.794997566555828 ; loss: 0.1453852711567369; accuracy: 0.819\n",
            "epoch:[ 119 ], cost: 11.406019152552945 ; loss: 0.14491378409536504; accuracy: 0.819375\n",
            "epoch:[ 120 ], cost: 11.610907251199022 ; loss: 0.1445570398679851; accuracy: 0.820875\n",
            "epoch:[ 121 ], cost: 11.338004178214916 ; loss: 0.14581107791357545; accuracy: 0.82025\n",
            "epoch:[ 122 ], cost: 11.372929074051198 ; loss: 0.1446649739775223; accuracy: 0.820625\n",
            "epoch:[ 123 ], cost: 12.039456178046102 ; loss: 0.14633186107696733; accuracy: 0.8205\n",
            "epoch:[ 124 ], cost: 11.250254895838879 ; loss: 0.14563054006913673; accuracy: 0.81775\n",
            "epoch:[ 125 ], cost: 11.568884911453768 ; loss: 0.14524138908396117; accuracy: 0.820625\n",
            "epoch:[ 126 ], cost: 10.894703669970017 ; loss: 0.14680345071793582; accuracy: 0.81975\n",
            "epoch:[ 127 ], cost: 11.379005110956454 ; loss: 0.14453025080503698; accuracy: 0.82125\n",
            "epoch:[ 128 ], cost: 11.651961187275402 ; loss: 0.1443135644697624; accuracy: 0.820875\n",
            "epoch:[ 129 ], cost: 11.429451006271247 ; loss: 0.1444810024089945; accuracy: 0.820625\n",
            "epoch:[ 130 ], cost: 11.767877545117617 ; loss: 0.1448646194684073; accuracy: 0.820375\n",
            "epoch:[ 131 ], cost: 11.023342530260939 ; loss: 0.14619032514103866; accuracy: 0.81925\n",
            "epoch:[ 132 ], cost: 11.5548825388534 ; loss: 0.14450131350227943; accuracy: 0.822125\n",
            "epoch:[ 133 ], cost: 11.773086272553485 ; loss: 0.14572104838220193; accuracy: 0.820375\n",
            "epoch:[ 134 ], cost: 11.043246915361232 ; loss: 0.1461952384543322; accuracy: 0.818875\n",
            "epoch:[ 135 ], cost: 11.650305833760743 ; loss: 0.1443782921538349; accuracy: 0.82175\n",
            "epoch:[ 136 ], cost: 11.643426475247631 ; loss: 0.14401842294566222; accuracy: 0.818625\n",
            "epoch:[ 137 ], cost: 11.489691923356556 ; loss: 0.14436682131779605; accuracy: 0.8195\n",
            "epoch:[ 138 ], cost: 11.857315831755654 ; loss: 0.14532112284276827; accuracy: 0.82025\n",
            "epoch:[ 139 ], cost: 11.090200101484971 ; loss: 0.14642855769649885; accuracy: 0.818875\n",
            "epoch:[ 140 ], cost: 11.47426813500683 ; loss: 0.14430755859141084; accuracy: 0.823\n",
            "epoch:[ 141 ], cost: 11.682987627976473 ; loss: 0.14521458919104102; accuracy: 0.8205\n",
            "epoch:[ 142 ], cost: 11.476766878075953 ; loss: 0.14460762094556118; accuracy: 0.818375\n",
            "epoch:[ 143 ], cost: 11.218178898518993 ; loss: 0.1454284030988574; accuracy: 0.81925\n",
            "epoch:[ 144 ], cost: 11.87684915966513 ; loss: 0.14604697279877416; accuracy: 0.8215\n",
            "epoch:[ 145 ], cost: 11.198545868275287 ; loss: 0.14576153031023067; accuracy: 0.819\n",
            "epoch:[ 146 ], cost: 11.281812581513691 ; loss: 0.14460031576983404; accuracy: 0.82125\n",
            "epoch:[ 147 ], cost: 11.87797303515708 ; loss: 0.14631395990404944; accuracy: 0.821125\n",
            "epoch:[ 148 ], cost: 11.239603599958501 ; loss: 0.14508913812598437; accuracy: 0.817875\n",
            "epoch:[ 149 ], cost: 11.561445129491855 ; loss: 0.144519361141801; accuracy: 0.821625\n",
            "epoch:[ 150 ], cost: 11.648398817184047 ; loss: 0.1454267838774747; accuracy: 0.821875\n",
            "epoch:[ 151 ], cost: 11.562506305580786 ; loss: 0.14479360040966993; accuracy: 0.81975\n",
            "epoch:[ 152 ], cost: 11.41371465951982 ; loss: 0.14412890514163865; accuracy: 0.8205\n",
            "epoch:[ 153 ], cost: 11.596664966342642 ; loss: 0.14466964220890569; accuracy: 0.8195\n",
            "epoch:[ 154 ], cost: 11.293366531004974 ; loss: 0.14537265708864897; accuracy: 0.8195\n",
            "epoch:[ 155 ], cost: 11.276691360779838 ; loss: 0.1449032318694941; accuracy: 0.82025\n",
            "epoch:[ 156 ], cost: 11.59976601719561 ; loss: 0.14484955548772852; accuracy: 0.8215\n",
            "epoch:[ 157 ], cost: 11.101519636561378 ; loss: 0.1453292282907252; accuracy: 0.8185\n",
            "epoch:[ 158 ], cost: 11.486823211421532 ; loss: 0.14456109175164322; accuracy: 0.822375\n",
            "epoch:[ 159 ], cost: 11.397475719145783 ; loss: 0.14444340873143874; accuracy: 0.822125\n",
            "epoch:[ 160 ], cost: 11.274085051298051 ; loss: 0.14534529412168984; accuracy: 0.821125\n",
            "epoch:[ 161 ], cost: 11.47137787829518 ; loss: 0.14422416306558086; accuracy: 0.81925\n",
            "epoch:[ 162 ], cost: 11.162469728515957 ; loss: 0.144884241830917; accuracy: 0.8215\n",
            "epoch:[ 163 ], cost: 11.412954502181965 ; loss: 0.14537960675226752; accuracy: 0.821625\n",
            "epoch:[ 164 ], cost: 11.350604126938721 ; loss: 0.14464932738907196; accuracy: 0.822375\n",
            "epoch:[ 165 ], cost: 11.606038956093798 ; loss: 0.1463059800405494; accuracy: 0.819625\n",
            "epoch:[ 166 ], cost: 11.091389355234863 ; loss: 0.14496485455142857; accuracy: 0.819875\n",
            "epoch:[ 167 ], cost: 11.667622985815347 ; loss: 0.14523502651595904; accuracy: 0.8205\n",
            "epoch:[ 168 ], cost: 11.00868208323411 ; loss: 0.1453303607819895; accuracy: 0.81825\n",
            "epoch:[ 169 ], cost: 11.637443514269375 ; loss: 0.1449947558430286; accuracy: 0.82175\n",
            "epoch:[ 170 ], cost: 11.013179640529046 ; loss: 0.1450719444807635; accuracy: 0.81825\n",
            "epoch:[ 171 ], cost: 11.589108441447948 ; loss: 0.14504013336383076; accuracy: 0.82075\n",
            "epoch:[ 172 ], cost: 11.342491712464145 ; loss: 0.14470104890660157; accuracy: 0.81825\n",
            "epoch:[ 173 ], cost: 11.578206300229837 ; loss: 0.14530456309951978; accuracy: 0.81925\n",
            "epoch:[ 174 ], cost: 10.825527665067732 ; loss: 0.14644834069149798; accuracy: 0.818375\n",
            "epoch:[ 175 ], cost: 11.56692463359602 ; loss: 0.14545201751403727; accuracy: 0.822125\n",
            "epoch:[ 176 ], cost: 11.46563350716366 ; loss: 0.14473281161055782; accuracy: 0.8185\n",
            "epoch:[ 177 ], cost: 11.365191932441267 ; loss: 0.1444757997545142; accuracy: 0.819375\n",
            "epoch:[ 178 ], cost: 11.317710512788244 ; loss: 0.14445396664699006; accuracy: 0.81875\n",
            "epoch:[ 179 ], cost: 11.241139267727803 ; loss: 0.14493128586744985; accuracy: 0.82075\n",
            "epoch:[ 180 ], cost: 11.574058523684123 ; loss: 0.14552681739653633; accuracy: 0.819625\n",
            "epoch:[ 181 ], cost: 10.942824238539457 ; loss: 0.14585856494902186; accuracy: 0.819375\n",
            "epoch:[ 182 ], cost: 11.237906222711965 ; loss: 0.1449448516326491; accuracy: 0.82225\n",
            "epoch:[ 183 ], cost: 11.241522366182325 ; loss: 0.14399987306163592; accuracy: 0.820875\n",
            "epoch:[ 184 ], cost: 11.255691190576835 ; loss: 0.14422267818641643; accuracy: 0.82075\n",
            "epoch:[ 185 ], cost: 11.157806534546268 ; loss: 0.14573509703952614; accuracy: 0.820375\n",
            "epoch:[ 186 ], cost: 11.468586023745514 ; loss: 0.14449496568246292; accuracy: 0.8195\n",
            "epoch:[ 187 ], cost: 11.122930392248085 ; loss: 0.14467247815920334; accuracy: 0.820625\n",
            "epoch:[ 188 ], cost: 11.25928805413037 ; loss: 0.1442607870597042; accuracy: 0.821375\n",
            "epoch:[ 189 ], cost: 11.25772733812089 ; loss: 0.14501213585539824; accuracy: 0.819875\n",
            "epoch:[ 190 ], cost: 11.160309150369919 ; loss: 0.14528445439024973; accuracy: 0.82125\n",
            "epoch:[ 191 ], cost: 11.365449985969336 ; loss: 0.1442613752810155; accuracy: 0.821\n",
            "epoch:[ 192 ], cost: 11.375513150414774 ; loss: 0.1444003944222625; accuracy: 0.8195\n",
            "epoch:[ 193 ], cost: 11.647111054210637 ; loss: 0.14579710936173348; accuracy: 0.82025\n",
            "epoch:[ 194 ], cost: 10.91825792829042 ; loss: 0.14571512824293148; accuracy: 0.819375\n",
            "epoch:[ 195 ], cost: 11.309447608842433 ; loss: 0.1450971182102662; accuracy: 0.822625\n",
            "epoch:[ 196 ], cost: 11.09858414875953 ; loss: 0.1451209581858965; accuracy: 0.820625\n",
            "epoch:[ 197 ], cost: 11.263894707645147 ; loss: 0.14435585382964583; accuracy: 0.8215\n",
            "epoch:[ 198 ], cost: 11.283196466149587 ; loss: 0.1443610472125417; accuracy: 0.820125\n",
            "epoch:[ 199 ], cost: 11.18826872406096 ; loss: 0.14531381355330683; accuracy: 0.820625\n",
            "epoch:[ 200 ], cost: 11.286516266241422 ; loss: 0.14431130506460627; accuracy: 0.820875\n",
            "epoch:[ 201 ], cost: 11.06203079222026 ; loss: 0.14485763990386014; accuracy: 0.822125\n",
            "epoch:[ 202 ], cost: 11.022716054563189 ; loss: 0.1447128403802937; accuracy: 0.821125\n",
            "epoch:[ 203 ], cost: 11.123904405958093 ; loss: 0.14431571162238524; accuracy: 0.822375\n",
            "epoch:[ 204 ], cost: 11.145499733498184 ; loss: 0.1446977372618577; accuracy: 0.8205\n",
            "epoch:[ 205 ], cost: 11.189651894269568 ; loss: 0.14410796507909607; accuracy: 0.821375\n",
            "epoch:[ 206 ], cost: 11.227232513143507 ; loss: 0.14381750079446126; accuracy: 0.820125\n",
            "epoch:[ 207 ], cost: 11.275611276267979 ; loss: 0.14406769334943487; accuracy: 0.820625\n",
            "epoch:[ 208 ], cost: 11.055465189313834 ; loss: 0.14503458906580075; accuracy: 0.82075\n",
            "epoch:[ 209 ], cost: 11.147923445761332 ; loss: 0.14463531151460493; accuracy: 0.8215\n",
            "epoch:[ 210 ], cost: 11.153898820722556 ; loss: 0.14410897269834028; accuracy: 0.82175\n",
            "epoch:[ 211 ], cost: 11.624670967545033 ; loss: 0.14526200756147228; accuracy: 0.821125\n",
            "epoch:[ 212 ], cost: 10.681327069169697 ; loss: 0.14570521825143132; accuracy: 0.81925\n",
            "epoch:[ 213 ], cost: 11.083794001404124 ; loss: 0.14506163251376897; accuracy: 0.82425\n",
            "epoch:[ 214 ], cost: 10.80968779953134 ; loss: 0.14454676420570314; accuracy: 0.8225\n",
            "epoch:[ 215 ], cost: 11.101512311395044 ; loss: 0.14403512748117428; accuracy: 0.82275\n",
            "epoch:[ 216 ], cost: 10.87504313828147 ; loss: 0.14411686953705832; accuracy: 0.82025\n",
            "epoch:[ 217 ], cost: 11.272675544373095 ; loss: 0.14471081633962204; accuracy: 0.8215\n",
            "epoch:[ 218 ], cost: 10.758635687625276 ; loss: 0.1445892409169425; accuracy: 0.821125\n",
            "epoch:[ 219 ], cost: 11.153067856266638 ; loss: 0.1446653124205853; accuracy: 0.8235\n",
            "epoch:[ 220 ], cost: 10.922062840564715 ; loss: 0.14395147424242682; accuracy: 0.8205\n",
            "epoch:[ 221 ], cost: 10.957946177235872 ; loss: 0.14414775250971704; accuracy: 0.821\n",
            "epoch:[ 222 ], cost: 10.74753465584321 ; loss: 0.14464932435922065; accuracy: 0.821875\n",
            "epoch:[ 223 ], cost: 11.145912088485757 ; loss: 0.14408044803295977; accuracy: 0.8215\n",
            "epoch:[ 224 ], cost: 10.589379732694875 ; loss: 0.14520989101853826; accuracy: 0.82075\n",
            "epoch:[ 225 ], cost: 10.996671620653359 ; loss: 0.1439707972707726; accuracy: 0.82225\n",
            "epoch:[ 226 ], cost: 10.923427988860173 ; loss: 0.1436401272164073; accuracy: 0.82175\n",
            "epoch:[ 227 ], cost: 10.870243022875197 ; loss: 0.14348960662858642; accuracy: 0.821625\n",
            "epoch:[ 228 ], cost: 11.036479224677203 ; loss: 0.145438123673787; accuracy: 0.821375\n",
            "epoch:[ 229 ], cost: 10.813463745329205 ; loss: 0.14458914822561444; accuracy: 0.823\n",
            "epoch:[ 230 ], cost: 10.83083599492745 ; loss: 0.1445671072738994; accuracy: 0.821625\n",
            "epoch:[ 231 ], cost: 10.84748348327464 ; loss: 0.1439293526814762; accuracy: 0.823\n",
            "epoch:[ 232 ], cost: 10.884349376415168 ; loss: 0.1435401155966304; accuracy: 0.82125\n",
            "epoch:[ 233 ], cost: 10.93631586500923 ; loss: 0.1440861027332173; accuracy: 0.82125\n",
            "epoch:[ 234 ], cost: 10.603818030222104 ; loss: 0.14421046783562216; accuracy: 0.821375\n",
            "epoch:[ 235 ], cost: 10.625457799229494 ; loss: 0.1438980022696249; accuracy: 0.822625\n",
            "epoch:[ 236 ], cost: 10.782831732913172 ; loss: 0.14403461461601388; accuracy: 0.822875\n",
            "epoch:[ 237 ], cost: 10.566489939885653 ; loss: 0.1439296466965699; accuracy: 0.8215\n",
            "epoch:[ 238 ], cost: 10.972479157995654 ; loss: 0.14410447674512608; accuracy: 0.82325\n",
            "epoch:[ 239 ], cost: 10.57807234464867 ; loss: 0.14419381934738174; accuracy: 0.820375\n",
            "epoch:[ 240 ], cost: 10.860147180174689 ; loss: 0.14368403817110956; accuracy: 0.822375\n",
            "epoch:[ 241 ], cost: 10.475122715974225 ; loss: 0.1441461352783867; accuracy: 0.821\n",
            "epoch:[ 242 ], cost: 10.958077714459158 ; loss: 0.14409236070900164; accuracy: 0.82275\n",
            "epoch:[ 243 ], cost: 10.32191597980855 ; loss: 0.14510147470652618; accuracy: 0.82025\n",
            "epoch:[ 244 ], cost: 10.827269665742556 ; loss: 0.14365671423142937; accuracy: 0.82175\n",
            "epoch:[ 245 ], cost: 10.681299664672617 ; loss: 0.14365457404014664; accuracy: 0.822125\n",
            "epoch:[ 246 ], cost: 11.011131810767383 ; loss: 0.14401653190012614; accuracy: 0.822125\n",
            "epoch:[ 247 ], cost: 10.173421421169303 ; loss: 0.1457609120332686; accuracy: 0.82025\n",
            "epoch:[ 248 ], cost: 10.795417274922162 ; loss: 0.14397058575227675; accuracy: 0.82325\n",
            "epoch:[ 249 ], cost: 10.967932192620495 ; loss: 0.14383787867663683; accuracy: 0.821875\n",
            "epoch:[ 250 ], cost: 10.51092462575113 ; loss: 0.14378285044810907; accuracy: 0.8205\n",
            "epoch:[ 251 ], cost: 10.85266593332891 ; loss: 0.14363052744718116; accuracy: 0.82275\n",
            "epoch:[ 252 ], cost: 10.473733015275501 ; loss: 0.14359847139638446; accuracy: 0.821875\n",
            "epoch:[ 253 ], cost: 10.758366205968594 ; loss: 0.14357943706235524; accuracy: 0.823125\n",
            "epoch:[ 254 ], cost: 10.61257972106778 ; loss: 0.14362974598166725; accuracy: 0.821375\n",
            "epoch:[ 255 ], cost: 10.86601460305079 ; loss: 0.14398349246585196; accuracy: 0.823625\n",
            "epoch:[ 256 ], cost: 10.367012761928585 ; loss: 0.14476554073361395; accuracy: 0.820375\n",
            "epoch:[ 257 ], cost: 10.734665241315668 ; loss: 0.14539695173354925; accuracy: 0.823625\n",
            "epoch:[ 258 ], cost: 10.161201956006085 ; loss: 0.1450819414553149; accuracy: 0.8205\n",
            "epoch:[ 259 ], cost: 10.763181247471719 ; loss: 0.14437028944725716; accuracy: 0.824875\n",
            "epoch:[ 260 ], cost: 10.409565463806665 ; loss: 0.14465259167824127; accuracy: 0.821\n",
            "epoch:[ 261 ], cost: 10.819444269027487 ; loss: 0.1439865550863941; accuracy: 0.822375\n",
            "epoch:[ 262 ], cost: 10.719327801144734 ; loss: 0.14386516881928857; accuracy: 0.822125\n",
            "epoch:[ 263 ], cost: 10.64871016312394 ; loss: 0.1433236780706881; accuracy: 0.821375\n",
            "epoch:[ 264 ], cost: 10.510431730396842 ; loss: 0.14321591861174063; accuracy: 0.821625\n",
            "epoch:[ 265 ], cost: 10.829870849566582 ; loss: 0.1439409851597155; accuracy: 0.823125\n",
            "epoch:[ 266 ], cost: 10.083587598733 ; loss: 0.14478290561401952; accuracy: 0.819875\n",
            "epoch:[ 267 ], cost: 10.610385909349155 ; loss: 0.14340141267129072; accuracy: 0.825\n",
            "epoch:[ 268 ], cost: 10.411643842500686 ; loss: 0.14368280949332116; accuracy: 0.822125\n",
            "epoch:[ 269 ], cost: 10.621052855951888 ; loss: 0.1434134134556005; accuracy: 0.82375\n",
            "epoch:[ 270 ], cost: 10.56314175741159 ; loss: 0.1441066086101485; accuracy: 0.82225\n",
            "epoch:[ 271 ], cost: 10.197101802516915 ; loss: 0.14419626114486847; accuracy: 0.821375\n",
            "epoch:[ 272 ], cost: 10.569287788987952 ; loss: 0.14355949272671528; accuracy: 0.82325\n",
            "epoch:[ 273 ], cost: 10.261524198708992 ; loss: 0.14371551257639686; accuracy: 0.82075\n",
            "epoch:[ 274 ], cost: 10.541973717310462 ; loss: 0.14335213465481453; accuracy: 0.8235\n",
            "epoch:[ 275 ], cost: 10.3971451757923 ; loss: 0.1434316650657405; accuracy: 0.823\n",
            "epoch:[ 276 ], cost: 10.496710628423427 ; loss: 0.1446243668163962; accuracy: 0.82275\n",
            "epoch:[ 277 ], cost: 10.4669996689567 ; loss: 0.14392302425462902; accuracy: 0.821375\n",
            "epoch:[ 278 ], cost: 10.471199702573044 ; loss: 0.14329036670586986; accuracy: 0.82425\n",
            "epoch:[ 279 ], cost: 10.563195389534139 ; loss: 0.14323283883027238; accuracy: 0.82325\n",
            "epoch:[ 280 ], cost: 10.198987684752556 ; loss: 0.14384163767161776; accuracy: 0.822125\n",
            "epoch:[ 281 ], cost: 10.54663181147401 ; loss: 0.1431415567130815; accuracy: 0.82425\n",
            "epoch:[ 282 ], cost: 10.29918386772149 ; loss: 0.14323328216888523; accuracy: 0.821875\n",
            "epoch:[ 283 ], cost: 10.615827905612118 ; loss: 0.14349761887106702; accuracy: 0.8245\n",
            "epoch:[ 284 ], cost: 9.831705776971507 ; loss: 0.14585749086591146; accuracy: 0.82075\n",
            "epoch:[ 285 ], cost: 10.50935768094971 ; loss: 0.14332513654282314; accuracy: 0.824875\n",
            "epoch:[ 286 ], cost: 10.399496345402103 ; loss: 0.14395411032483382; accuracy: 0.822875\n",
            "epoch:[ 287 ], cost: 10.16876452127001 ; loss: 0.14444312294850728; accuracy: 0.822375\n",
            "epoch:[ 288 ], cost: 9.830417886014382 ; loss: 0.1451538388410131; accuracy: 0.82275\n",
            "epoch:[ 289 ], cost: 10.1283492395026 ; loss: 0.14412597567684; accuracy: 0.825875\n",
            "epoch:[ 290 ], cost: 10.234231017039182 ; loss: 0.14390633083202659; accuracy: 0.82475\n",
            "epoch:[ 291 ], cost: 9.987550280223052 ; loss: 0.1440816584540506; accuracy: 0.823375\n",
            "epoch:[ 292 ], cost: 10.253791573847677 ; loss: 0.14365626013392227; accuracy: 0.824\n",
            "epoch:[ 293 ], cost: 9.760752415076276 ; loss: 0.1451698424574161; accuracy: 0.822875\n",
            "epoch:[ 294 ], cost: 10.311410532545537 ; loss: 0.14398411472880723; accuracy: 0.825875\n",
            "epoch:[ 295 ], cost: 10.152441982547222 ; loss: 0.14334562187138272; accuracy: 0.82375\n",
            "epoch:[ 296 ], cost: 10.146649918105982 ; loss: 0.1434050718781689; accuracy: 0.824375\n",
            "epoch:[ 297 ], cost: 10.406824650915913 ; loss: 0.14406872863963582; accuracy: 0.825125\n",
            "epoch:[ 298 ], cost: 9.920547281892453 ; loss: 0.1443055243442913; accuracy: 0.822\n",
            "epoch:[ 299 ], cost: 10.132439472867583 ; loss: 0.14359300968366961; accuracy: 0.826375\n",
            "epoch:[ 300 ], cost: 10.106577428150613 ; loss: 0.14377048358640246; accuracy: 0.825375\n",
            "epoch:[ 301 ], cost: 10.062585979322696 ; loss: 0.14368499389046538; accuracy: 0.825125\n",
            "epoch:[ 302 ], cost: 10.022467494426976 ; loss: 0.14345059983771238; accuracy: 0.824875\n",
            "epoch:[ 303 ], cost: 9.980963046457955 ; loss: 0.14362440911182286; accuracy: 0.825375\n",
            "epoch:[ 304 ], cost: 10.060016261817074 ; loss: 0.14298476257882567; accuracy: 0.824875\n",
            "epoch:[ 305 ], cost: 10.030826203306331 ; loss: 0.14268442680597007; accuracy: 0.825125\n",
            "epoch:[ 306 ], cost: 10.242220657410202 ; loss: 0.14341603705106837; accuracy: 0.824875\n",
            "epoch:[ 307 ], cost: 9.788485759629564 ; loss: 0.14400219656952837; accuracy: 0.824\n",
            "epoch:[ 308 ], cost: 10.494222155768211 ; loss: 0.14507502561932634; accuracy: 0.826125\n",
            "epoch:[ 309 ], cost: 9.933390658967197 ; loss: 0.1429509244894779; accuracy: 0.823\n",
            "epoch:[ 310 ], cost: 10.0203111062051 ; loss: 0.14293210822362828; accuracy: 0.826125\n",
            "epoch:[ 311 ], cost: 9.893802070825425 ; loss: 0.1428934085320068; accuracy: 0.82575\n",
            "epoch:[ 312 ], cost: 10.003993296252442 ; loss: 0.14268247640362067; accuracy: 0.82675\n",
            "epoch:[ 313 ], cost: 9.914642872379863 ; loss: 0.1430332280764487; accuracy: 0.82475\n",
            "epoch:[ 314 ], cost: 9.655307337447617 ; loss: 0.14433587053121716; accuracy: 0.826125\n",
            "epoch:[ 315 ], cost: 9.538095498743484 ; loss: 0.14415399980276558; accuracy: 0.826625\n",
            "epoch:[ 316 ], cost: 9.923601248648447 ; loss: 0.14299305802997236; accuracy: 0.8275\n",
            "epoch:[ 317 ], cost: 9.67509581588136 ; loss: 0.14318600444772334; accuracy: 0.825\n",
            "epoch:[ 318 ], cost: 9.728721307759347 ; loss: 0.14325546339819029; accuracy: 0.826625\n",
            "epoch:[ 319 ], cost: 9.731777701783658 ; loss: 0.14286150196583186; accuracy: 0.826375\n",
            "epoch:[ 320 ], cost: 9.635956756949584 ; loss: 0.14303624730188239; accuracy: 0.826\n",
            "epoch:[ 321 ], cost: 9.802857974976419 ; loss: 0.14246667553903022; accuracy: 0.827125\n",
            "epoch:[ 322 ], cost: 9.653193066028003 ; loss: 0.14251965966849156; accuracy: 0.82525\n",
            "epoch:[ 323 ], cost: 9.475493975377704 ; loss: 0.1432722090618009; accuracy: 0.824375\n",
            "epoch:[ 324 ], cost: 9.806382090573676 ; loss: 0.14317725701863612; accuracy: 0.826\n",
            "epoch:[ 325 ], cost: 9.507234696466906 ; loss: 0.14301618162692858; accuracy: 0.82575\n",
            "epoch:[ 326 ], cost: 9.74278439563152 ; loss: 0.14356348540052555; accuracy: 0.826375\n",
            "epoch:[ 327 ], cost: 9.51259239631068 ; loss: 0.1430116291584503; accuracy: 0.825375\n",
            "epoch:[ 328 ], cost: 9.629402614680163 ; loss: 0.14280740967099473; accuracy: 0.8265\n",
            "epoch:[ 329 ], cost: 9.45359427414903 ; loss: 0.1428495822201524; accuracy: 0.825625\n",
            "epoch:[ 330 ], cost: 9.616302354516908 ; loss: 0.1424595145982978; accuracy: 0.826375\n",
            "epoch:[ 331 ], cost: 9.369476767782432 ; loss: 0.14306842667085867; accuracy: 0.826375\n",
            "epoch:[ 332 ], cost: 9.573390983592668 ; loss: 0.1429745384499734; accuracy: 0.827875\n",
            "epoch:[ 333 ], cost: 9.231392970182057 ; loss: 0.14306952901735434; accuracy: 0.825875\n",
            "epoch:[ 334 ], cost: 9.416169041151907 ; loss: 0.14265076761709697; accuracy: 0.829125\n",
            "epoch:[ 335 ], cost: 9.162440648430525 ; loss: 0.14369799295192823; accuracy: 0.82575\n",
            "epoch:[ 336 ], cost: 9.495077661321805 ; loss: 0.1423415153586591; accuracy: 0.82775\n",
            "epoch:[ 337 ], cost: 9.275311009640221 ; loss: 0.1423196949166147; accuracy: 0.826125\n",
            "epoch:[ 338 ], cost: 9.575694374218873 ; loss: 0.14337392048773775; accuracy: 0.827625\n",
            "epoch:[ 339 ], cost: 9.088182989397033 ; loss: 0.14270231840219014; accuracy: 0.82575\n",
            "epoch:[ 340 ], cost: 9.416761647596458 ; loss: 0.14226634150393375; accuracy: 0.8295\n",
            "epoch:[ 341 ], cost: 9.234914886996267 ; loss: 0.1419708998833581; accuracy: 0.826875\n",
            "epoch:[ 342 ], cost: 9.278390477576703 ; loss: 0.14205220409353717; accuracy: 0.828125\n",
            "epoch:[ 343 ], cost: 9.248179964163375 ; loss: 0.1422723129401927; accuracy: 0.828125\n",
            "epoch:[ 344 ], cost: 9.142651606901623 ; loss: 0.1419077193072268; accuracy: 0.828\n",
            "epoch:[ 345 ], cost: 9.409079918002845 ; loss: 0.142156315451333; accuracy: 0.829125\n",
            "epoch:[ 346 ], cost: 9.076393692120947 ; loss: 0.14263135662681822; accuracy: 0.827125\n",
            "epoch:[ 347 ], cost: 9.037536561332127 ; loss: 0.14263606768188142; accuracy: 0.828\n",
            "epoch:[ 348 ], cost: 9.152295628921198 ; loss: 0.1417155953058487; accuracy: 0.82975\n",
            "epoch:[ 349 ], cost: 9.226790427901452 ; loss: 0.14141117220243027; accuracy: 0.828375\n",
            "epoch:[ 350 ], cost: 9.064631716329451 ; loss: 0.14199151077327812; accuracy: 0.82775\n",
            "epoch:[ 351 ], cost: 9.264449322990542 ; loss: 0.14251123567985977; accuracy: 0.828625\n",
            "epoch:[ 352 ], cost: 9.242312837282846 ; loss: 0.1422226987289151; accuracy: 0.826375\n",
            "epoch:[ 353 ], cost: 9.15139823854825 ; loss: 0.14161299454201418; accuracy: 0.828125\n",
            "epoch:[ 354 ], cost: 9.12847067706488 ; loss: 0.14193199208400323; accuracy: 0.828375\n",
            "epoch:[ 355 ], cost: 9.210197288818712 ; loss: 0.14212653085705054; accuracy: 0.828125\n",
            "epoch:[ 356 ], cost: 9.010053001822456 ; loss: 0.1428942985193187; accuracy: 0.8285\n",
            "epoch:[ 357 ], cost: 9.38479429724344 ; loss: 0.14234671375107455; accuracy: 0.828625\n",
            "epoch:[ 358 ], cost: 8.840927980946104 ; loss: 0.14297225714497974; accuracy: 0.82825\n",
            "epoch:[ 359 ], cost: 9.378346656740296 ; loss: 0.14232457789527092; accuracy: 0.831\n",
            "epoch:[ 360 ], cost: 9.185275069257013 ; loss: 0.14205922773170934; accuracy: 0.825625\n",
            "epoch:[ 361 ], cost: 9.451942187998736 ; loss: 0.1419772640255216; accuracy: 0.82825\n",
            "epoch:[ 362 ], cost: 8.860477222424004 ; loss: 0.14270300807208852; accuracy: 0.825625\n",
            "epoch:[ 363 ], cost: 9.246680608954508 ; loss: 0.1422923563978399; accuracy: 0.830125\n",
            "epoch:[ 364 ], cost: 8.946081156414694 ; loss: 0.1420571362605838; accuracy: 0.82775\n",
            "epoch:[ 365 ], cost: 9.11082186869477 ; loss: 0.14195759191866755; accuracy: 0.829625\n",
            "epoch:[ 366 ], cost: 8.936253607744463 ; loss: 0.1423321353868186; accuracy: 0.8285\n",
            "epoch:[ 367 ], cost: 9.123447840750993 ; loss: 0.14248156844477677; accuracy: 0.828875\n",
            "epoch:[ 368 ], cost: 9.108760552733603 ; loss: 0.14222171766778569; accuracy: 0.828625\n",
            "epoch:[ 369 ], cost: 9.295432648477345 ; loss: 0.14187951512952002; accuracy: 0.82825\n",
            "epoch:[ 370 ], cost: 9.0681852441273 ; loss: 0.14293033450177836; accuracy: 0.828125\n",
            "epoch:[ 371 ], cost: 9.150423250854566 ; loss: 0.14235656793374954; accuracy: 0.828\n",
            "epoch:[ 372 ], cost: 9.076403967052341 ; loss: 0.14170172124974542; accuracy: 0.82875\n",
            "epoch:[ 373 ], cost: 9.111602736815472 ; loss: 0.1411196291739495; accuracy: 0.82975\n",
            "epoch:[ 374 ], cost: 9.233970949294504 ; loss: 0.14138429471399483; accuracy: 0.829375\n",
            "epoch:[ 375 ], cost: 8.791974730667832 ; loss: 0.14338843174196272; accuracy: 0.829125\n",
            "epoch:[ 376 ], cost: 9.272578293191074 ; loss: 0.14350468307153014; accuracy: 0.829375\n",
            "epoch:[ 377 ], cost: 9.157144794223806 ; loss: 0.14229899466867943; accuracy: 0.828375\n",
            "epoch:[ 378 ], cost: 9.26549264049148 ; loss: 0.14191602518412327; accuracy: 0.827625\n",
            "epoch:[ 379 ], cost: 9.130277314715178 ; loss: 0.14201524208505056; accuracy: 0.827125\n",
            "epoch:[ 380 ], cost: 9.123305656795651 ; loss: 0.14216282770767605; accuracy: 0.82875\n",
            "epoch:[ 381 ], cost: 9.026026888568143 ; loss: 0.1415872744272295; accuracy: 0.827375\n",
            "epoch:[ 382 ], cost: 9.12155011060291 ; loss: 0.14131291355690662; accuracy: 0.829125\n",
            "epoch:[ 383 ], cost: 8.990499575854393 ; loss: 0.141565560663154; accuracy: 0.828625\n",
            "epoch:[ 384 ], cost: 9.257168780245026 ; loss: 0.14174008457339657; accuracy: 0.8295\n",
            "epoch:[ 385 ], cost: 8.937145050008857 ; loss: 0.14165091698697632; accuracy: 0.82725\n",
            "epoch:[ 386 ], cost: 9.211783135399132 ; loss: 0.14206161957750038; accuracy: 0.829\n",
            "epoch:[ 387 ], cost: 9.013447188139702 ; loss: 0.1429324927095192; accuracy: 0.827375\n",
            "epoch:[ 388 ], cost: 9.233221113758676 ; loss: 0.14333727561580745; accuracy: 0.828125\n",
            "epoch:[ 389 ], cost: 8.872888746940248 ; loss: 0.14231591327808882; accuracy: 0.827875\n",
            "epoch:[ 390 ], cost: 8.810835184211017 ; loss: 0.14206335654070085; accuracy: 0.8295\n",
            "epoch:[ 391 ], cost: 8.916812515775526 ; loss: 0.14147967546566517; accuracy: 0.82925\n",
            "epoch:[ 392 ], cost: 8.827088588168252 ; loss: 0.14152617617041433; accuracy: 0.828375\n",
            "epoch:[ 393 ], cost: 9.005953033125435 ; loss: 0.14225048431275167; accuracy: 0.828875\n",
            "epoch:[ 394 ], cost: 8.604966349217843 ; loss: 0.14275566153386351; accuracy: 0.827625\n",
            "epoch:[ 395 ], cost: 8.941985303436006 ; loss: 0.14137484864483332; accuracy: 0.828875\n",
            "epoch:[ 396 ], cost: 8.85956409842763 ; loss: 0.1417500925249047; accuracy: 0.827875\n",
            "epoch:[ 397 ], cost: 8.887755627135629 ; loss: 0.14210438970052422; accuracy: 0.8295\n",
            "epoch:[ 398 ], cost: 8.634590336521041 ; loss: 0.1424719498858409; accuracy: 0.828375\n",
            "epoch:[ 399 ], cost: 8.931269093507149 ; loss: 0.14166973414963044; accuracy: 0.82925\n",
            "epoch:[ 400 ], cost: 8.93715472017577 ; loss: 0.1417641262583806; accuracy: 0.82875\n",
            "epoch:[ 401 ], cost: 8.773282013438356 ; loss: 0.14206226360851115; accuracy: 0.82825\n",
            "epoch:[ 402 ], cost: 8.833098058893341 ; loss: 0.1416905241261685; accuracy: 0.829625\n",
            "epoch:[ 403 ], cost: 9.022917480781466 ; loss: 0.14189460727258194; accuracy: 0.827875\n",
            "epoch:[ 404 ], cost: 8.547276222291224 ; loss: 0.14246335283143094; accuracy: 0.827\n",
            "epoch:[ 405 ], cost: 8.82782744706412 ; loss: 0.14182703871786437; accuracy: 0.828625\n",
            "epoch:[ 406 ], cost: 8.74780955664284 ; loss: 0.14234184933201127; accuracy: 0.82825\n",
            "epoch:[ 407 ], cost: 8.879512306977219 ; loss: 0.1422556733896248; accuracy: 0.82725\n",
            "epoch:[ 408 ], cost: 8.568264994519918 ; loss: 0.14352643896227438; accuracy: 0.829125\n",
            "epoch:[ 409 ], cost: 8.77570276774915 ; loss: 0.14190161336038262; accuracy: 0.828375\n",
            "epoch:[ 410 ], cost: 8.804884233256907 ; loss: 0.14164762240418785; accuracy: 0.828375\n",
            "epoch:[ 411 ], cost: 8.809212335713095 ; loss: 0.1418722361435552; accuracy: 0.8285\n",
            "epoch:[ 412 ], cost: 8.64991689332146 ; loss: 0.14204552655681976; accuracy: 0.828625\n",
            "epoch:[ 413 ], cost: 8.826660019461679 ; loss: 0.1419357079448975; accuracy: 0.828375\n",
            "epoch:[ 414 ], cost: 8.831219252976677 ; loss: 0.14276670623458296; accuracy: 0.828\n",
            "epoch:[ 415 ], cost: 8.938478276800769 ; loss: 0.14135365422947854; accuracy: 0.82575\n",
            "epoch:[ 416 ], cost: 8.690675781315354 ; loss: 0.14205414720815854; accuracy: 0.8275\n",
            "epoch:[ 417 ], cost: 8.866171832843676 ; loss: 0.14223010675800218; accuracy: 0.828\n",
            "epoch:[ 418 ], cost: 8.959734507391266 ; loss: 0.1415167514051422; accuracy: 0.82975\n",
            "epoch:[ 419 ], cost: 8.698938895891443 ; loss: 0.1422512756600282; accuracy: 0.8275\n",
            "epoch:[ 420 ], cost: 8.954207486956944 ; loss: 0.14194626364515955; accuracy: 0.828125\n",
            "epoch:[ 421 ], cost: 8.606779939554121 ; loss: 0.14227839824853794; accuracy: 0.827125\n",
            "epoch:[ 422 ], cost: 8.866850574810734 ; loss: 0.14182543844131865; accuracy: 0.828125\n",
            "epoch:[ 423 ], cost: 8.577069189269356 ; loss: 0.14232299749684285; accuracy: 0.826625\n",
            "epoch:[ 424 ], cost: 8.894726132185724 ; loss: 0.14174241283293953; accuracy: 0.8285\n",
            "epoch:[ 425 ], cost: 8.8518229855076 ; loss: 0.14149342567487744; accuracy: 0.826875\n",
            "epoch:[ 426 ], cost: 8.921028078957692 ; loss: 0.14209554447292255; accuracy: 0.82775\n",
            "epoch:[ 427 ], cost: 8.44287700169401 ; loss: 0.1432337322088493; accuracy: 0.828125\n",
            "epoch:[ 428 ], cost: 8.825950288559266 ; loss: 0.14209708273937544; accuracy: 0.829625\n",
            "epoch:[ 429 ], cost: 8.749043038440028 ; loss: 0.1414269217149809; accuracy: 0.826\n",
            "epoch:[ 430 ], cost: 8.86024496641888 ; loss: 0.1420550398540787; accuracy: 0.827875\n",
            "epoch:[ 431 ], cost: 8.607216714875262 ; loss: 0.1421943825626924; accuracy: 0.82625\n",
            "epoch:[ 432 ], cost: 8.789467222808781 ; loss: 0.14150612223470352; accuracy: 0.828375\n",
            "epoch:[ 433 ], cost: 8.878226514932305 ; loss: 0.14239861290224382; accuracy: 0.828125\n",
            "epoch:[ 434 ], cost: 8.95185223520066 ; loss: 0.14177732834015355; accuracy: 0.82625\n",
            "epoch:[ 435 ], cost: 8.667810252682724 ; loss: 0.1422798994165703; accuracy: 0.826875\n",
            "epoch:[ 436 ], cost: 8.99959619602985 ; loss: 0.1422240306166674; accuracy: 0.828375\n",
            "epoch:[ 437 ], cost: 8.80514873612574 ; loss: 0.14172363202117705; accuracy: 0.826125\n",
            "epoch:[ 438 ], cost: 8.998633098192494 ; loss: 0.14179385155639207; accuracy: 0.82875\n",
            "epoch:[ 439 ], cost: 9.018486955079073 ; loss: 0.14256314903886516; accuracy: 0.825125\n",
            "epoch:[ 440 ], cost: 8.521616752676454 ; loss: 0.14293117198130909; accuracy: 0.827125\n",
            "epoch:[ 441 ], cost: 8.656009053815275 ; loss: 0.14313834024799296; accuracy: 0.82975\n",
            "epoch:[ 442 ], cost: 8.893733056011923 ; loss: 0.1418317560414822; accuracy: 0.82575\n",
            "epoch:[ 443 ], cost: 8.615983943392104 ; loss: 0.1426394429585015; accuracy: 0.826625\n",
            "epoch:[ 444 ], cost: 8.906125581699051 ; loss: 0.14159420436489745; accuracy: 0.82775\n",
            "epoch:[ 445 ], cost: 8.970080394155138 ; loss: 0.14227032896650726; accuracy: 0.8275\n",
            "epoch:[ 446 ], cost: 8.620027606891753 ; loss: 0.14277445846983075; accuracy: 0.825875\n",
            "epoch:[ 447 ], cost: 8.893587274991441 ; loss: 0.14215986717326853; accuracy: 0.828125\n",
            "epoch:[ 448 ], cost: 8.986510269026642 ; loss: 0.14185405800166018; accuracy: 0.824875\n",
            "epoch:[ 449 ], cost: 8.564027918761104 ; loss: 0.1431034833147811; accuracy: 0.826\n",
            "epoch:[ 450 ], cost: 8.969058797582768 ; loss: 0.14189706447485093; accuracy: 0.8285\n",
            "epoch:[ 451 ], cost: 8.527759545697755 ; loss: 0.1431935853363848; accuracy: 0.82725\n",
            "epoch:[ 452 ], cost: 8.955234274954663 ; loss: 0.14189516720321296; accuracy: 0.8285\n",
            "epoch:[ 453 ], cost: 8.966832968521675 ; loss: 0.14174210952741864; accuracy: 0.82575\n",
            "epoch:[ 454 ], cost: 8.74601658553733 ; loss: 0.14240000838222402; accuracy: 0.827625\n",
            "epoch:[ 455 ], cost: 8.868068991909057 ; loss: 0.14219366186686005; accuracy: 0.8275\n",
            "epoch:[ 456 ], cost: 8.969774388211881 ; loss: 0.14247279596151696; accuracy: 0.827875\n",
            "epoch:[ 457 ], cost: 9.080037808044654 ; loss: 0.1417496477925471; accuracy: 0.824875\n",
            "epoch:[ 458 ], cost: 8.535588206012138 ; loss: 0.14407683070705504; accuracy: 0.827625\n",
            "epoch:[ 459 ], cost: 8.921778450341906 ; loss: 0.14189716812660075; accuracy: 0.829\n",
            "epoch:[ 460 ], cost: 8.98913469044936 ; loss: 0.14132782597142582; accuracy: 0.82825\n",
            "epoch:[ 461 ], cost: 8.95611554809751 ; loss: 0.1414381376196557; accuracy: 0.827875\n",
            "epoch:[ 462 ], cost: 9.061360744848946 ; loss: 0.1428504137005398; accuracy: 0.828\n",
            "epoch:[ 463 ], cost: 8.599022475992783 ; loss: 0.1427203216796579; accuracy: 0.827\n",
            "epoch:[ 464 ], cost: 9.025724383787372 ; loss: 0.14217275509025365; accuracy: 0.828125\n",
            "epoch:[ 465 ], cost: 8.946396856584581 ; loss: 0.14179852153917397; accuracy: 0.825625\n",
            "epoch:[ 466 ], cost: 8.996618861696476 ; loss: 0.14213367411716712; accuracy: 0.826875\n",
            "epoch:[ 467 ], cost: 8.745062846356184 ; loss: 0.1415354510957872; accuracy: 0.8255\n",
            "epoch:[ 468 ], cost: 8.914548345721915 ; loss: 0.1418472792072989; accuracy: 0.82875\n",
            "epoch:[ 469 ], cost: 8.784431183096508 ; loss: 0.14267122006829555; accuracy: 0.826625\n",
            "epoch:[ 470 ], cost: 8.902875162925435 ; loss: 0.14299309204853267; accuracy: 0.82475\n",
            "epoch:[ 471 ], cost: 8.610948999189512 ; loss: 0.14230517355191682; accuracy: 0.82775\n",
            "epoch:[ 472 ], cost: 8.686373459808442 ; loss: 0.14289294902289545; accuracy: 0.827\n",
            "epoch:[ 473 ], cost: 8.565325892957203 ; loss: 0.1429553559483949; accuracy: 0.83075\n",
            "epoch:[ 474 ], cost: 8.840833187384668 ; loss: 0.14161023733552613; accuracy: 0.829125\n",
            "epoch:[ 475 ], cost: 8.719986351656493 ; loss: 0.14154839562417076; accuracy: 0.827625\n",
            "epoch:[ 476 ], cost: 8.909497483738253 ; loss: 0.14277392493166596; accuracy: 0.8285\n",
            "epoch:[ 477 ], cost: 8.57931841713204 ; loss: 0.14313543133081877; accuracy: 0.826625\n",
            "epoch:[ 478 ], cost: 8.671151519072973 ; loss: 0.14249289273682844; accuracy: 0.828625\n",
            "epoch:[ 479 ], cost: 8.714776115875745 ; loss: 0.14174731307899016; accuracy: 0.831375\n",
            "epoch:[ 480 ], cost: 8.782808287659797 ; loss: 0.14097156803708516; accuracy: 0.827125\n",
            "epoch:[ 481 ], cost: 8.721687707142618 ; loss: 0.1411112168973103; accuracy: 0.828\n",
            "epoch:[ 482 ], cost: 8.797865765707169 ; loss: 0.14159028354175723; accuracy: 0.828125\n",
            "epoch:[ 483 ], cost: 8.810483789104286 ; loss: 0.14184947324796257; accuracy: 0.825875\n",
            "epoch:[ 484 ], cost: 8.551589332803806 ; loss: 0.14253935308671273; accuracy: 0.827375\n",
            "epoch:[ 485 ], cost: 8.830333162224537 ; loss: 0.14188244503397424; accuracy: 0.8275\n",
            "epoch:[ 486 ], cost: 8.532078401019742 ; loss: 0.14298966845712122; accuracy: 0.827375\n",
            "epoch:[ 487 ], cost: 8.84145191274972 ; loss: 0.14161825766869376; accuracy: 0.831\n",
            "epoch:[ 488 ], cost: 8.984300481241222 ; loss: 0.14247287567426192; accuracy: 0.82775\n",
            "epoch:[ 489 ], cost: 8.671818807533954 ; loss: 0.14263967183825543; accuracy: 0.8285\n",
            "epoch:[ 490 ], cost: 8.795957547059688 ; loss: 0.1418042199805426; accuracy: 0.827375\n",
            "epoch:[ 491 ], cost: 8.82985537050077 ; loss: 0.1423077400810258; accuracy: 0.829125\n",
            "epoch:[ 492 ], cost: 8.548588805999 ; loss: 0.14247181489214922; accuracy: 0.827\n",
            "epoch:[ 493 ], cost: 8.713169192485125 ; loss: 0.14174471935780963; accuracy: 0.830875\n",
            "epoch:[ 494 ], cost: 8.730914060785572 ; loss: 0.14158048835703282; accuracy: 0.8295\n",
            "epoch:[ 495 ], cost: 8.69294755033587 ; loss: 0.14177958948368793; accuracy: 0.82825\n",
            "epoch:[ 496 ], cost: 8.670098905606777 ; loss: 0.14203302875809856; accuracy: 0.828125\n",
            "epoch:[ 497 ], cost: 8.82944286404993 ; loss: 0.14158620612370398; accuracy: 0.829375\n",
            "epoch:[ 498 ], cost: 8.561034456124874 ; loss: 0.14181283814108933; accuracy: 0.828125\n",
            "epoch:[ 499 ], cost: 8.822705640942429 ; loss: 0.1414127436218599; accuracy: 0.828875\n",
            "epoch:[ 500 ], cost: 8.653589650670028 ; loss: 0.1417549715609908; accuracy: 0.829125\n",
            "epoch:[ 501 ], cost: 9.0488656012282 ; loss: 0.14254240784480976; accuracy: 0.830125\n",
            "epoch:[ 502 ], cost: 8.666201800241357 ; loss: 0.14251527902004868; accuracy: 0.827\n",
            "epoch:[ 503 ], cost: 8.651088422240433 ; loss: 0.14234231241289563; accuracy: 0.82825\n",
            "epoch:[ 504 ], cost: 8.851642802006848 ; loss: 0.14169158071069643; accuracy: 0.83025\n",
            "epoch:[ 505 ], cost: 8.799098062556695 ; loss: 0.14243364017782711; accuracy: 0.82775\n",
            "epoch:[ 506 ], cost: 8.557503345583168 ; loss: 0.14256689321484453; accuracy: 0.82875\n",
            "epoch:[ 507 ], cost: 8.647912696897027 ; loss: 0.1415661496994871; accuracy: 0.829875\n",
            "epoch:[ 508 ], cost: 8.885794099069937 ; loss: 0.14176882818083988; accuracy: 0.82925\n",
            "epoch:[ 509 ], cost: 8.632274376051381 ; loss: 0.1420062436183001; accuracy: 0.82825\n",
            "epoch:[ 510 ], cost: 9.052106819538585 ; loss: 0.14267442262943006; accuracy: 0.8295\n",
            "epoch:[ 511 ], cost: 8.356233675155384 ; loss: 0.14397683771888645; accuracy: 0.82775\n",
            "epoch:[ 512 ], cost: 8.615022431664203 ; loss: 0.14218209364172657; accuracy: 0.82925\n",
            "epoch:[ 513 ], cost: 8.817057993686634 ; loss: 0.1424708246324551; accuracy: 0.83\n",
            "epoch:[ 514 ], cost: 8.719796579640745 ; loss: 0.14256270514379132; accuracy: 0.829\n",
            "epoch:[ 515 ], cost: 8.807440909507966 ; loss: 0.14167966174188076; accuracy: 0.827875\n",
            "epoch:[ 516 ], cost: 8.660969494310551 ; loss: 0.14224263084028377; accuracy: 0.829375\n",
            "epoch:[ 517 ], cost: 8.930967906067885 ; loss: 0.14231331730948016; accuracy: 0.83\n",
            "epoch:[ 518 ], cost: 8.89451687709598 ; loss: 0.14228676771624998; accuracy: 0.82675\n",
            "epoch:[ 519 ], cost: 8.721910929240483 ; loss: 0.14244431742324007; accuracy: 0.830125\n",
            "epoch:[ 520 ], cost: 8.829272937310026 ; loss: 0.14179998013064268; accuracy: 0.827875\n",
            "epoch:[ 521 ], cost: 8.80222510656666 ; loss: 0.14270465742248517; accuracy: 0.829375\n",
            "epoch:[ 522 ], cost: 8.746504968630179 ; loss: 0.14229577502379073; accuracy: 0.82825\n",
            "epoch:[ 523 ], cost: 8.905875206426071 ; loss: 0.14171969441080473; accuracy: 0.829875\n",
            "epoch:[ 524 ], cost: 8.917954085026865 ; loss: 0.14154303939697419; accuracy: 0.828375\n",
            "epoch:[ 525 ], cost: 8.871282227135504 ; loss: 0.14203698184063782; accuracy: 0.82775\n",
            "epoch:[ 526 ], cost: 8.461045864757859 ; loss: 0.14391279524136968; accuracy: 0.82975\n",
            "epoch:[ 527 ], cost: 8.820774558851966 ; loss: 0.14202841918863948; accuracy: 0.83175\n",
            "epoch:[ 528 ], cost: 8.750662634536328 ; loss: 0.14141253983895966; accuracy: 0.82925\n",
            "epoch:[ 529 ], cost: 8.891131819258725 ; loss: 0.14128654095717047; accuracy: 0.8305\n",
            "epoch:[ 530 ], cost: 8.737121187980957 ; loss: 0.14300246014858645; accuracy: 0.829125\n",
            "epoch:[ 531 ], cost: 8.643926637772028 ; loss: 0.14348677258017062; accuracy: 0.83175\n",
            "epoch:[ 532 ], cost: 8.733086945226761 ; loss: 0.14187171428091172; accuracy: 0.82925\n",
            "epoch:[ 533 ], cost: 8.890552776064995 ; loss: 0.1420133726056669; accuracy: 0.831125\n",
            "epoch:[ 534 ], cost: 8.579167144874505 ; loss: 0.1422329899916082; accuracy: 0.829875\n",
            "epoch:[ 535 ], cost: 8.830602405510943 ; loss: 0.14171979752387298; accuracy: 0.829375\n",
            "epoch:[ 536 ], cost: 8.617871687297306 ; loss: 0.1420238485463065; accuracy: 0.829375\n",
            "epoch:[ 537 ], cost: 8.942520766684897 ; loss: 0.14250317512687138; accuracy: 0.83\n",
            "epoch:[ 538 ], cost: 8.682588268696918 ; loss: 0.14298026700284014; accuracy: 0.828125\n",
            "epoch:[ 539 ], cost: 8.727962372311021 ; loss: 0.1417620106889018; accuracy: 0.828\n",
            "epoch:[ 540 ], cost: 8.849563812057294 ; loss: 0.1415663003978185; accuracy: 0.83\n",
            "epoch:[ 541 ], cost: 8.712293837880642 ; loss: 0.14269797644738777; accuracy: 0.8305\n",
            "epoch:[ 542 ], cost: 8.870069075996113 ; loss: 0.14146798249495254; accuracy: 0.829375\n",
            "epoch:[ 543 ], cost: 8.842414908066054 ; loss: 0.14178511858868847; accuracy: 0.829375\n",
            "epoch:[ 544 ], cost: 8.825470653856854 ; loss: 0.143024163286638; accuracy: 0.828875\n",
            "epoch:[ 545 ], cost: 8.651793727047686 ; loss: 0.14213231669366008; accuracy: 0.8285\n",
            "epoch:[ 546 ], cost: 8.830619901974336 ; loss: 0.14198689795213243; accuracy: 0.831875\n",
            "epoch:[ 547 ], cost: 8.580045858010042 ; loss: 0.14261738876425095; accuracy: 0.830625\n",
            "epoch:[ 548 ], cost: 8.875292700847497 ; loss: 0.14175343015829076; accuracy: 0.83075\n",
            "epoch:[ 549 ], cost: 8.827282888726831 ; loss: 0.14159267917438123; accuracy: 0.83075\n",
            "epoch:[ 550 ], cost: 8.883043451859127 ; loss: 0.14127119256564083; accuracy: 0.829\n",
            "epoch:[ 551 ], cost: 8.853647318781572 ; loss: 0.14197584024987747; accuracy: 0.829\n",
            "epoch:[ 552 ], cost: 8.691790806038757 ; loss: 0.14246079586472765; accuracy: 0.829375\n",
            "epoch:[ 553 ], cost: 8.80260780937912 ; loss: 0.14147765656703196; accuracy: 0.829625\n",
            "epoch:[ 554 ], cost: 8.958105510866318 ; loss: 0.14152934949025955; accuracy: 0.8315\n",
            "epoch:[ 555 ], cost: 8.713533547442495 ; loss: 0.14216665279875712; accuracy: 0.828125\n",
            "epoch:[ 556 ], cost: 8.84496127163208 ; loss: 0.1415706462013725; accuracy: 0.830125\n",
            "epoch:[ 557 ], cost: 8.968410182978257 ; loss: 0.14190271754370462; accuracy: 0.8305\n",
            "epoch:[ 558 ], cost: 8.545718686811643 ; loss: 0.14309224931275843; accuracy: 0.829125\n",
            "epoch:[ 559 ], cost: 8.938988947002736 ; loss: 0.1415557310773038; accuracy: 0.83125\n",
            "epoch:[ 560 ], cost: 8.66245338108973 ; loss: 0.1423172054085215; accuracy: 0.83\n",
            "epoch:[ 561 ], cost: 8.975500475140652 ; loss: 0.1417118508414967; accuracy: 0.829625\n",
            "epoch:[ 562 ], cost: 8.52750347283541 ; loss: 0.14326821111791857; accuracy: 0.8295\n",
            "epoch:[ 563 ], cost: 8.98183786395846 ; loss: 0.14173272110500645; accuracy: 0.832\n",
            "epoch:[ 564 ], cost: 8.711535060039768 ; loss: 0.14204085565595814; accuracy: 0.831\n",
            "epoch:[ 565 ], cost: 8.828096137755395 ; loss: 0.141184414087128; accuracy: 0.831875\n",
            "epoch:[ 566 ], cost: 8.75775844768919 ; loss: 0.1413041799428126; accuracy: 0.83025\n",
            "epoch:[ 567 ], cost: 8.971319637736043 ; loss: 0.14186195627908393; accuracy: 0.831375\n",
            "epoch:[ 568 ], cost: 8.938824421570672 ; loss: 0.1422594155037477; accuracy: 0.829125\n",
            "epoch:[ 569 ], cost: 8.522825105257809 ; loss: 0.14328189085024293; accuracy: 0.830375\n",
            "epoch:[ 570 ], cost: 8.958874654641038 ; loss: 0.1414400034971491; accuracy: 0.8315\n",
            "epoch:[ 571 ], cost: 8.779573992301295 ; loss: 0.1422016564129355; accuracy: 0.8295\n",
            "epoch:[ 572 ], cost: 8.959403591395937 ; loss: 0.141897211869631; accuracy: 0.831\n",
            "epoch:[ 573 ], cost: 8.827037555415478 ; loss: 0.14184356368297485; accuracy: 0.829125\n",
            "epoch:[ 574 ], cost: 8.98081742416817 ; loss: 0.14192687516472194; accuracy: 0.83075\n",
            "epoch:[ 575 ], cost: 8.90690173038991 ; loss: 0.1417025952814859; accuracy: 0.829875\n",
            "epoch:[ 576 ], cost: 8.694208961589354 ; loss: 0.14238297218206197; accuracy: 0.83025\n",
            "epoch:[ 577 ], cost: 8.901182505218937 ; loss: 0.141587391649034; accuracy: 0.831625\n",
            "epoch:[ 578 ], cost: 8.907906132711352 ; loss: 0.14138045700147386; accuracy: 0.829625\n",
            "epoch:[ 579 ], cost: 8.75646524833345 ; loss: 0.1424503038869833; accuracy: 0.83125\n",
            "epoch:[ 580 ], cost: 8.798256359838518 ; loss: 0.14259040839701898; accuracy: 0.83025\n",
            "epoch:[ 581 ], cost: 8.956962316875105 ; loss: 0.1417722797854298; accuracy: 0.831625\n",
            "epoch:[ 582 ], cost: 8.66322006303179 ; loss: 0.14273159272390676; accuracy: 0.830125\n",
            "epoch:[ 583 ], cost: 9.015175876839942 ; loss: 0.14217928338336566; accuracy: 0.830875\n",
            "epoch:[ 584 ], cost: 8.935549741152444 ; loss: 0.14140103802391912; accuracy: 0.829625\n",
            "epoch:[ 585 ], cost: 8.704698209362258 ; loss: 0.1420905590514488; accuracy: 0.831\n",
            "epoch:[ 586 ], cost: 8.848305338852954 ; loss: 0.14172615798849256; accuracy: 0.8305\n",
            "epoch:[ 587 ], cost: 8.954382553986253 ; loss: 0.14242263364029198; accuracy: 0.830875\n",
            "epoch:[ 588 ], cost: 8.87907446682888 ; loss: 0.1422187463853958; accuracy: 0.830125\n",
            "epoch:[ 589 ], cost: 8.905876520640456 ; loss: 0.14129017655841045; accuracy: 0.829\n",
            "epoch:[ 590 ], cost: 8.93906195791092 ; loss: 0.14143407719272044; accuracy: 0.8305\n",
            "epoch:[ 591 ], cost: 8.890685826084505 ; loss: 0.14154783863152873; accuracy: 0.82925\n",
            "epoch:[ 592 ], cost: 8.782610876253864 ; loss: 0.14197053794618925; accuracy: 0.831875\n",
            "epoch:[ 593 ], cost: 8.93142377431853 ; loss: 0.14119809741790906; accuracy: 0.830625\n",
            "epoch:[ 594 ], cost: 8.84846110706384 ; loss: 0.14160405446948862; accuracy: 0.8305\n",
            "epoch:[ 595 ], cost: 8.991038240503105 ; loss: 0.1423044840169859; accuracy: 0.829625\n",
            "epoch:[ 596 ], cost: 8.841813156427257 ; loss: 0.14250680220639048; accuracy: 0.830625\n",
            "epoch:[ 597 ], cost: 8.847010955015435 ; loss: 0.14220826069788325; accuracy: 0.8285\n",
            "epoch:[ 598 ], cost: 8.719350550386363 ; loss: 0.1427544965899146; accuracy: 0.831125\n",
            "epoch:[ 599 ], cost: 8.955475384436081 ; loss: 0.1415340518188965; accuracy: 0.829875\n",
            "epoch:[ 600 ], cost: 8.867038193213563 ; loss: 0.1420320021209374; accuracy: 0.830875\n",
            "epoch:[ 601 ], cost: 8.93835107163888 ; loss: 0.14159575998210233; accuracy: 0.82775\n",
            "epoch:[ 602 ], cost: 8.743248601069727 ; loss: 0.14233566653788984; accuracy: 0.830125\n",
            "epoch:[ 603 ], cost: 8.92786250954733 ; loss: 0.1414615240530636; accuracy: 0.82975\n",
            "epoch:[ 604 ], cost: 8.974535762842352 ; loss: 0.1417908299780272; accuracy: 0.83025\n",
            "epoch:[ 605 ], cost: 8.922613839942251 ; loss: 0.1415572295440589; accuracy: 0.827625\n",
            "epoch:[ 606 ], cost: 8.676838644881043 ; loss: 0.1423476498986131; accuracy: 0.8295\n",
            "epoch:[ 607 ], cost: 8.971861307798786 ; loss: 0.1415802042796111; accuracy: 0.83225\n",
            "epoch:[ 608 ], cost: 8.9797924658708 ; loss: 0.14134614920986838; accuracy: 0.82875\n",
            "epoch:[ 609 ], cost: 8.839238388062025 ; loss: 0.14166936450466797; accuracy: 0.83025\n",
            "epoch:[ 610 ], cost: 9.10958902210282 ; loss: 0.14217559833465065; accuracy: 0.829625\n",
            "epoch:[ 611 ], cost: 8.635764422134919 ; loss: 0.1428110514514549; accuracy: 0.829125\n",
            "epoch:[ 612 ], cost: 9.006384453282909 ; loss: 0.14150914040207777; accuracy: 0.83\n",
            "epoch:[ 613 ], cost: 8.89247356978653 ; loss: 0.1416280511459219; accuracy: 0.829375\n",
            "epoch:[ 614 ], cost: 8.953292755041325 ; loss: 0.14123349809196328; accuracy: 0.828875\n",
            "epoch:[ 615 ], cost: 8.879302841260289 ; loss: 0.14141152681859376; accuracy: 0.829125\n",
            "epoch:[ 616 ], cost: 8.85228716862717 ; loss: 0.1422289488800323; accuracy: 0.83025\n",
            "epoch:[ 617 ], cost: 8.889386019174042 ; loss: 0.14150716482262055; accuracy: 0.8295\n",
            "epoch:[ 618 ], cost: 8.982559181506659 ; loss: 0.14117187633459133; accuracy: 0.83025\n",
            "epoch:[ 619 ], cost: 8.901395698182268 ; loss: 0.14108228987747506; accuracy: 0.83\n",
            "epoch:[ 620 ], cost: 9.058292327073795 ; loss: 0.1415265315007648; accuracy: 0.830375\n",
            "epoch:[ 621 ], cost: 8.66044032125875 ; loss: 0.14280632702874407; accuracy: 0.828875\n",
            "epoch:[ 622 ], cost: 9.032771967631627 ; loss: 0.1416561376491989; accuracy: 0.831\n",
            "epoch:[ 623 ], cost: 8.87638488583756 ; loss: 0.14148158920962642; accuracy: 0.828875\n",
            "epoch:[ 624 ], cost: 9.001281815695991 ; loss: 0.1412712651303906; accuracy: 0.830625\n",
            "epoch:[ 625 ], cost: 8.903659726159923 ; loss: 0.1416387728664303; accuracy: 0.829125\n",
            "epoch:[ 626 ], cost: 9.024578601040423 ; loss: 0.14263448719072805; accuracy: 0.829625\n",
            "epoch:[ 627 ], cost: 8.792283530188564 ; loss: 0.14200197517406876; accuracy: 0.829625\n",
            "epoch:[ 628 ], cost: 9.027186468862006 ; loss: 0.1421492950071921; accuracy: 0.829625\n",
            "epoch:[ 629 ], cost: 8.892324461142572 ; loss: 0.14228320679349168; accuracy: 0.8285\n",
            "epoch:[ 630 ], cost: 8.839582963433037 ; loss: 0.14220666187615336; accuracy: 0.830125\n",
            "epoch:[ 631 ], cost: 8.867862770568575 ; loss: 0.1418880074709475; accuracy: 0.828625\n",
            "epoch:[ 632 ], cost: 9.061905028170177 ; loss: 0.14154651874914237; accuracy: 0.831\n",
            "epoch:[ 633 ], cost: 8.716472764382763 ; loss: 0.1424162733913185; accuracy: 0.830125\n",
            "epoch:[ 634 ], cost: 8.963622164580684 ; loss: 0.14189483144988316; accuracy: 0.829875\n",
            "epoch:[ 635 ], cost: 8.805775660036916 ; loss: 0.14224964718535948; accuracy: 0.828625\n",
            "epoch:[ 636 ], cost: 8.78058932273385 ; loss: 0.1418823085050312; accuracy: 0.830125\n",
            "epoch:[ 637 ], cost: 8.922308829253698 ; loss: 0.14159698998096099; accuracy: 0.83\n",
            "epoch:[ 638 ], cost: 8.920627540436112 ; loss: 0.14133522250225075; accuracy: 0.829375\n",
            "epoch:[ 639 ], cost: 8.931502977918854 ; loss: 0.14167722273976466; accuracy: 0.829\n",
            "epoch:[ 640 ], cost: 8.775602232749254 ; loss: 0.14184763275910603; accuracy: 0.829\n",
            "epoch:[ 641 ], cost: 9.043928077200198 ; loss: 0.14176311228666388; accuracy: 0.83\n",
            "epoch:[ 642 ], cost: 8.767977082246926 ; loss: 0.14178719538781864; accuracy: 0.8275\n",
            "epoch:[ 643 ], cost: 8.990259179868367 ; loss: 0.14214900765096458; accuracy: 0.830875\n",
            "epoch:[ 644 ], cost: 8.815360125057957 ; loss: 0.1417613515013209; accuracy: 0.829875\n",
            "epoch:[ 645 ], cost: 8.951291385040715 ; loss: 0.14167215605257866; accuracy: 0.83\n",
            "epoch:[ 646 ], cost: 8.832190878207452 ; loss: 0.1420012992222488; accuracy: 0.829625\n",
            "epoch:[ 647 ], cost: 8.853184160116044 ; loss: 0.14161499953954257; accuracy: 0.82925\n",
            "epoch:[ 648 ], cost: 8.878335469226352 ; loss: 0.1415392856077077; accuracy: 0.8305\n",
            "epoch:[ 649 ], cost: 8.895431573232674 ; loss: 0.14146340483285189; accuracy: 0.8285\n",
            "epoch:[ 650 ], cost: 8.888038594135638 ; loss: 0.14140087736269782; accuracy: 0.829125\n",
            "epoch:[ 651 ], cost: 8.895563065008396 ; loss: 0.14123882695169004; accuracy: 0.829125\n",
            "epoch:[ 652 ], cost: 8.931418479631564 ; loss: 0.14126525970027717; accuracy: 0.8295\n",
            "epoch:[ 653 ], cost: 8.822670878338982 ; loss: 0.14261117136643878; accuracy: 0.82875\n",
            "epoch:[ 654 ], cost: 8.806467713328061 ; loss: 0.14256923053197887; accuracy: 0.82825\n",
            "epoch:[ 655 ], cost: 8.863152069647601 ; loss: 0.1416445612268974; accuracy: 0.83075\n",
            "epoch:[ 656 ], cost: 8.922849820182863 ; loss: 0.14154640547234065; accuracy: 0.829625\n",
            "epoch:[ 657 ], cost: 8.788080435692823 ; loss: 0.14191219023708687; accuracy: 0.82975\n",
            "epoch:[ 658 ], cost: 9.038043718866325 ; loss: 0.1418472555774732; accuracy: 0.828875\n",
            "epoch:[ 659 ], cost: 8.800099104537916 ; loss: 0.14171261680650302; accuracy: 0.827625\n",
            "epoch:[ 660 ], cost: 8.844495140456651 ; loss: 0.14159621523527618; accuracy: 0.83075\n",
            "epoch:[ 661 ], cost: 8.946895213408295 ; loss: 0.14179470112252368; accuracy: 0.830625\n",
            "epoch:[ 662 ], cost: 8.942211348192846 ; loss: 0.14183049319690913; accuracy: 0.82975\n",
            "epoch:[ 663 ], cost: 8.905885652675359 ; loss: 0.1415293876522758; accuracy: 0.8295\n",
            "epoch:[ 664 ], cost: 8.973721699067323 ; loss: 0.14176185056617285; accuracy: 0.829875\n",
            "epoch:[ 665 ], cost: 8.9738710861441 ; loss: 0.1416286073384527; accuracy: 0.828125\n",
            "epoch:[ 666 ], cost: 8.742244509600692 ; loss: 0.14250367475753245; accuracy: 0.829375\n",
            "epoch:[ 667 ], cost: 8.968809662832006 ; loss: 0.14194416701206705; accuracy: 0.829875\n",
            "epoch:[ 668 ], cost: 8.865034268133238 ; loss: 0.142476291602578; accuracy: 0.83175\n",
            "epoch:[ 669 ], cost: 9.111600634990005 ; loss: 0.14187048958516527; accuracy: 0.829125\n",
            "epoch:[ 670 ], cost: 8.995922136657825 ; loss: 0.14175757652399612; accuracy: 0.82775\n",
            "epoch:[ 671 ], cost: 9.110769150963865 ; loss: 0.14161075940906767; accuracy: 0.828125\n",
            "epoch:[ 672 ], cost: 8.814646899037841 ; loss: 0.14182437828003128; accuracy: 0.82875\n",
            "epoch:[ 673 ], cost: 8.905934260343825 ; loss: 0.14156682370884477; accuracy: 0.8305\n",
            "epoch:[ 674 ], cost: 8.985253305094597 ; loss: 0.14191745596642813; accuracy: 0.831375\n",
            "epoch:[ 675 ], cost: 8.946008491676196 ; loss: 0.14114737846366252; accuracy: 0.829125\n",
            "epoch:[ 676 ], cost: 8.942211306814972 ; loss: 0.14124768842046678; accuracy: 0.82975\n",
            "epoch:[ 677 ], cost: 8.949994414815489 ; loss: 0.14163140212017997; accuracy: 0.83075\n",
            "epoch:[ 678 ], cost: 8.950171019013332 ; loss: 0.14239182843950743; accuracy: 0.830625\n",
            "epoch:[ 679 ], cost: 8.942353377321203 ; loss: 0.14246236364823442; accuracy: 0.829125\n",
            "epoch:[ 680 ], cost: 8.769982695785744 ; loss: 0.1424148203324817; accuracy: 0.83075\n",
            "epoch:[ 681 ], cost: 8.965832311220307 ; loss: 0.14139127574418558; accuracy: 0.82975\n",
            "epoch:[ 682 ], cost: 8.983298588349946 ; loss: 0.14162236502632025; accuracy: 0.828125\n",
            "epoch:[ 683 ], cost: 8.766348837465827 ; loss: 0.14218961465272112; accuracy: 0.829625\n",
            "epoch:[ 684 ], cost: 8.955894983036076 ; loss: 0.14138207983645887; accuracy: 0.830625\n",
            "epoch:[ 685 ], cost: 8.955660773468436 ; loss: 0.1414569614354767; accuracy: 0.829875\n",
            "epoch:[ 686 ], cost: 8.841556418132122 ; loss: 0.1419427824985449; accuracy: 0.829875\n",
            "epoch:[ 687 ], cost: 9.03626939562303 ; loss: 0.14176649831407961; accuracy: 0.83\n",
            "epoch:[ 688 ], cost: 8.776761699102796 ; loss: 0.14242787994735187; accuracy: 0.829625\n",
            "epoch:[ 689 ], cost: 8.947640242433323 ; loss: 0.14194630756984686; accuracy: 0.831375\n",
            "epoch:[ 690 ], cost: 8.844864593341114 ; loss: 0.1421423463275293; accuracy: 0.8295\n",
            "epoch:[ 691 ], cost: 8.935533367653415 ; loss: 0.1413135445867575; accuracy: 0.831375\n",
            "epoch:[ 692 ], cost: 8.929078768815414 ; loss: 0.1418502435624995; accuracy: 0.82975\n",
            "epoch:[ 693 ], cost: 9.010233793238752 ; loss: 0.14218126385919289; accuracy: 0.830625\n",
            "epoch:[ 694 ], cost: 8.880781828991 ; loss: 0.1416569221066495; accuracy: 0.8295\n",
            "epoch:[ 695 ], cost: 8.982649808708924 ; loss: 0.1416677066923701; accuracy: 0.830625\n",
            "epoch:[ 696 ], cost: 9.090204228602722 ; loss: 0.14205801137979854; accuracy: 0.829625\n",
            "epoch:[ 697 ], cost: 8.764075104851122 ; loss: 0.14244705656209247; accuracy: 0.82825\n",
            "epoch:[ 698 ], cost: 8.917909684220191 ; loss: 0.14144268749123304; accuracy: 0.829625\n",
            "epoch:[ 699 ], cost: 8.909676326508862 ; loss: 0.14135286501726307; accuracy: 0.82975\n",
            "epoch:[ 700 ], cost: 8.8274156931135 ; loss: 0.1416772500437936; accuracy: 0.830875\n",
            "epoch:[ 701 ], cost: 8.949908615660712 ; loss: 0.14159188511737664; accuracy: 0.830375\n",
            "epoch:[ 702 ], cost: 8.88436542042213 ; loss: 0.1424619899563551; accuracy: 0.831625\n",
            "epoch:[ 703 ], cost: 8.763841658882253 ; loss: 0.142171054655946; accuracy: 0.82925\n",
            "epoch:[ 704 ], cost: 8.98266318396293 ; loss: 0.14169380826265832; accuracy: 0.831875\n",
            "epoch:[ 705 ], cost: 8.924415819233936 ; loss: 0.14138708919736245; accuracy: 0.8295\n",
            "epoch:[ 706 ], cost: 8.903963249500475 ; loss: 0.14128447727651922; accuracy: 0.829625\n",
            "epoch:[ 707 ], cost: 8.91507126936887 ; loss: 0.1411286987634625; accuracy: 0.830125\n",
            "epoch:[ 708 ], cost: 9.008907781824421 ; loss: 0.14208263063675827; accuracy: 0.830375\n",
            "epoch:[ 709 ], cost: 8.86466834345856 ; loss: 0.14120549808098576; accuracy: 0.829375\n",
            "epoch:[ 710 ], cost: 9.06342644171857 ; loss: 0.142726116867428; accuracy: 0.82975\n",
            "epoch:[ 711 ], cost: 8.668358966299325 ; loss: 0.14261705655527185; accuracy: 0.8295\n",
            "epoch:[ 712 ], cost: 8.926442758816581 ; loss: 0.14167908090408152; accuracy: 0.831375\n",
            "epoch:[ 713 ], cost: 8.933185652223212 ; loss: 0.1417387866749698; accuracy: 0.82975\n",
            "epoch:[ 714 ], cost: 8.776675426447678 ; loss: 0.1431797575089599; accuracy: 0.829875\n",
            "epoch:[ 715 ], cost: 8.859279954349176 ; loss: 0.14170712845229996; accuracy: 0.82925\n",
            "epoch:[ 716 ], cost: 8.905148978068524 ; loss: 0.14142551885314633; accuracy: 0.8305\n",
            "epoch:[ 717 ], cost: 8.996097388178931 ; loss: 0.14199819159735871; accuracy: 0.82925\n",
            "epoch:[ 718 ], cost: 8.750181431241192 ; loss: 0.1422372110283926; accuracy: 0.829375\n",
            "epoch:[ 719 ], cost: 8.885028482079932 ; loss: 0.14120868939004458; accuracy: 0.830875\n",
            "epoch:[ 720 ], cost: 8.989175923481666 ; loss: 0.14135692813689874; accuracy: 0.829375\n",
            "epoch:[ 721 ], cost: 8.757302821496996 ; loss: 0.14254787148230846; accuracy: 0.8305\n",
            "epoch:[ 722 ], cost: 9.029103397819966 ; loss: 0.14132614723910816; accuracy: 0.830875\n",
            "epoch:[ 723 ], cost: 8.836035118399828 ; loss: 0.14196113951877978; accuracy: 0.829125\n",
            "epoch:[ 724 ], cost: 8.896831555860032 ; loss: 0.14259414898652634; accuracy: 0.832125\n",
            "epoch:[ 725 ], cost: 8.8798745356189 ; loss: 0.14179454996514296; accuracy: 0.82875\n",
            "epoch:[ 726 ], cost: 9.05066338091096 ; loss: 0.14133915354193477; accuracy: 0.8305\n",
            "epoch:[ 727 ], cost: 8.847281551176941 ; loss: 0.14166254402621192; accuracy: 0.829875\n",
            "epoch:[ 728 ], cost: 9.031733992544218 ; loss: 0.14166855622299976; accuracy: 0.830875\n",
            "epoch:[ 729 ], cost: 8.776849967342534 ; loss: 0.1424563842653733; accuracy: 0.8305\n",
            "epoch:[ 730 ], cost: 8.920325027677762 ; loss: 0.14151471553269498; accuracy: 0.8305\n",
            "epoch:[ 731 ], cost: 8.948396898229642 ; loss: 0.1412089994543939; accuracy: 0.831\n",
            "epoch:[ 732 ], cost: 8.911322239100663 ; loss: 0.14115462902674933; accuracy: 0.83025\n",
            "epoch:[ 733 ], cost: 9.020936182784862 ; loss: 0.14242404843250275; accuracy: 0.831875\n",
            "epoch:[ 734 ], cost: 8.530261317238422 ; loss: 0.1432815784995796; accuracy: 0.82925\n",
            "epoch:[ 735 ], cost: 8.780146462799257 ; loss: 0.14184105295283633; accuracy: 0.830875\n",
            "epoch:[ 736 ], cost: 8.94573783361836 ; loss: 0.1414780027032198; accuracy: 0.830875\n",
            "epoch:[ 737 ], cost: 8.728258425594618 ; loss: 0.14208778324976076; accuracy: 0.831\n",
            "epoch:[ 738 ], cost: 8.955761214581416 ; loss: 0.14142045424478497; accuracy: 0.830625\n",
            "epoch:[ 739 ], cost: 8.79320835094327 ; loss: 0.14212888438272614; accuracy: 0.830875\n",
            "epoch:[ 740 ], cost: 9.03154114399618 ; loss: 0.14212989301702936; accuracy: 0.831625\n",
            "epoch:[ 741 ], cost: 8.827931257848089 ; loss: 0.14134653847470513; accuracy: 0.828875\n",
            "epoch:[ 742 ], cost: 8.900083128949168 ; loss: 0.14163585383765168; accuracy: 0.831875\n",
            "epoch:[ 743 ], cost: 8.852505629784012 ; loss: 0.1416206025059811; accuracy: 0.8305\n",
            "epoch:[ 744 ], cost: 8.857292356752241 ; loss: 0.14181417471239047; accuracy: 0.832125\n",
            "epoch:[ 745 ], cost: 8.910643103594458 ; loss: 0.14197743225631443; accuracy: 0.831625\n",
            "epoch:[ 746 ], cost: 9.066771893282755 ; loss: 0.14203648216710005; accuracy: 0.830375\n",
            "epoch:[ 747 ], cost: 8.847540875739554 ; loss: 0.1415087287527624; accuracy: 0.82875\n",
            "epoch:[ 748 ], cost: 8.906271288718198 ; loss: 0.14117233559681905; accuracy: 0.83175\n",
            "epoch:[ 749 ], cost: 8.821615169575619 ; loss: 0.14148372378199917; accuracy: 0.83075\n",
            "epoch:[ 750 ], cost: 9.040879517635043 ; loss: 0.14193946819240205; accuracy: 0.832375\n",
            "epoch:[ 751 ], cost: 8.822075553855779 ; loss: 0.14233038684378746; accuracy: 0.829625\n",
            "epoch:[ 752 ], cost: 8.82689916955013 ; loss: 0.14154564665242292; accuracy: 0.830375\n",
            "epoch:[ 753 ], cost: 8.906650518284735 ; loss: 0.14129648984322035; accuracy: 0.83025\n",
            "epoch:[ 754 ], cost: 8.973412111563363 ; loss: 0.14186288188028676; accuracy: 0.83125\n",
            "epoch:[ 755 ], cost: 8.761394943288773 ; loss: 0.14228011289864773; accuracy: 0.8295\n",
            "epoch:[ 756 ], cost: 9.0156141855684 ; loss: 0.14127670239376935; accuracy: 0.83125\n",
            "epoch:[ 757 ], cost: 8.78607196073952 ; loss: 0.14199217940599812; accuracy: 0.83075\n",
            "epoch:[ 758 ], cost: 9.12764963896993 ; loss: 0.14191802030315376; accuracy: 0.830875\n",
            "epoch:[ 759 ], cost: 8.71598733823831 ; loss: 0.14255871038783766; accuracy: 0.82825\n",
            "epoch:[ 760 ], cost: 9.080285090416133 ; loss: 0.1415641860062442; accuracy: 0.83025\n",
            "epoch:[ 761 ], cost: 9.011629348080097 ; loss: 0.14117508891375724; accuracy: 0.830625\n",
            "epoch:[ 762 ], cost: 9.071012185983886 ; loss: 0.14137906002138162; accuracy: 0.829875\n",
            "epoch:[ 763 ], cost: 8.854807462317767 ; loss: 0.14209734973142485; accuracy: 0.829125\n",
            "epoch:[ 764 ], cost: 8.934734531085033 ; loss: 0.14151823374901545; accuracy: 0.829125\n",
            "epoch:[ 765 ], cost: 8.919172920736878 ; loss: 0.1416639082570961; accuracy: 0.832\n",
            "epoch:[ 766 ], cost: 9.035024375511533 ; loss: 0.14181191430798318; accuracy: 0.830875\n",
            "epoch:[ 767 ], cost: 8.758364949976464 ; loss: 0.1427392773788929; accuracy: 0.830375\n",
            "epoch:[ 768 ], cost: 8.995061107645684 ; loss: 0.14139879777078251; accuracy: 0.83025\n",
            "epoch:[ 769 ], cost: 9.02668664762996 ; loss: 0.1417299609113813; accuracy: 0.83025\n",
            "epoch:[ 770 ], cost: 8.873549292522261 ; loss: 0.1416191901630877; accuracy: 0.83025\n",
            "epoch:[ 771 ], cost: 9.074930460671434 ; loss: 0.14124567253011505; accuracy: 0.83025\n",
            "epoch:[ 772 ], cost: 8.855668004190196 ; loss: 0.141841071018408; accuracy: 0.830125\n",
            "epoch:[ 773 ], cost: 9.012190527021096 ; loss: 0.1415315938495167; accuracy: 0.831\n",
            "epoch:[ 774 ], cost: 8.84358445772143 ; loss: 0.14182071517932018; accuracy: 0.830625\n",
            "epoch:[ 775 ], cost: 8.987640652282215 ; loss: 0.14113603437020847; accuracy: 0.830875\n",
            "epoch:[ 776 ], cost: 8.905439609494358 ; loss: 0.14138912685141178; accuracy: 0.831375\n",
            "epoch:[ 777 ], cost: 9.162527768645154 ; loss: 0.14201419102928964; accuracy: 0.832\n",
            "epoch:[ 778 ], cost: 8.957884761258233 ; loss: 0.1419357493887972; accuracy: 0.829375\n",
            "epoch:[ 779 ], cost: 8.974029976310048 ; loss: 0.14142531445992296; accuracy: 0.83075\n",
            "epoch:[ 780 ], cost: 8.931018796267923 ; loss: 0.14126329535410134; accuracy: 0.831\n",
            "epoch:[ 781 ], cost: 8.951628256664018 ; loss: 0.14162642597562958; accuracy: 0.83125\n",
            "epoch:[ 782 ], cost: 8.827031052328973 ; loss: 0.141517505070987; accuracy: 0.83025\n",
            "epoch:[ 783 ], cost: 9.13920697547318 ; loss: 0.1426574698392464; accuracy: 0.83075\n",
            "epoch:[ 784 ], cost: 8.724754181801206 ; loss: 0.14255526937975158; accuracy: 0.83025\n",
            "epoch:[ 785 ], cost: 8.904713206851087 ; loss: 0.14161838197153986; accuracy: 0.830875\n",
            "epoch:[ 786 ], cost: 8.851948472356874 ; loss: 0.14147284405131333; accuracy: 0.829625\n",
            "epoch:[ 787 ], cost: 8.939305847092271 ; loss: 0.14131537931161228; accuracy: 0.83075\n",
            "epoch:[ 788 ], cost: 8.839887092625254 ; loss: 0.14144430995358948; accuracy: 0.83\n",
            "epoch:[ 789 ], cost: 8.873404638738121 ; loss: 0.14167375283030584; accuracy: 0.831875\n",
            "epoch:[ 790 ], cost: 8.717693420393898 ; loss: 0.14250104164510405; accuracy: 0.831375\n",
            "epoch:[ 791 ], cost: 9.052426923832865 ; loss: 0.1416526039036096; accuracy: 0.830625\n",
            "epoch:[ 792 ], cost: 9.09171848185869 ; loss: 0.14226992983909667; accuracy: 0.829375\n",
            "epoch:[ 793 ], cost: 8.83409554520442 ; loss: 0.1421378155793518; accuracy: 0.83025\n",
            "epoch:[ 794 ], cost: 8.989421012840186 ; loss: 0.14179639820268633; accuracy: 0.831\n",
            "epoch:[ 795 ], cost: 9.032096965069828 ; loss: 0.14158382924492652; accuracy: 0.829625\n",
            "epoch:[ 796 ], cost: 8.873220095734641 ; loss: 0.14195814181448885; accuracy: 0.830375\n",
            "epoch:[ 797 ], cost: 8.968929247790253 ; loss: 0.1417823897185666; accuracy: 0.83\n",
            "epoch:[ 798 ], cost: 9.009408915142435 ; loss: 0.1419213316408472; accuracy: 0.831\n",
            "epoch:[ 799 ], cost: 8.767082231802235 ; loss: 0.14204981469415592; accuracy: 0.829875\n",
            "epoch:[ 800 ], cost: 8.931216070475267 ; loss: 0.14124202293196458; accuracy: 0.83025\n",
            "epoch:[ 801 ], cost: 9.007823756326205 ; loss: 0.1413287356200109; accuracy: 0.830375\n",
            "epoch:[ 802 ], cost: 8.880209040661937 ; loss: 0.1417864296159721; accuracy: 0.830375\n",
            "epoch:[ 803 ], cost: 9.01149588401094 ; loss: 0.1414938668253895; accuracy: 0.83075\n",
            "epoch:[ 804 ], cost: 8.899116305779465 ; loss: 0.14146803392881954; accuracy: 0.82975\n",
            "epoch:[ 805 ], cost: 8.997011049415454 ; loss: 0.14166998422001909; accuracy: 0.831625\n",
            "epoch:[ 806 ], cost: 8.879680865521195 ; loss: 0.14222635706019038; accuracy: 0.830875\n",
            "epoch:[ 807 ], cost: 8.856293669482467 ; loss: 0.14218677138161825; accuracy: 0.82975\n",
            "epoch:[ 808 ], cost: 8.910909422520623 ; loss: 0.1414676634252712; accuracy: 0.831125\n",
            "epoch:[ 809 ], cost: 9.073398733411494 ; loss: 0.14200127366130483; accuracy: 0.831\n",
            "epoch:[ 810 ], cost: 8.840336904359013 ; loss: 0.1421071787153508; accuracy: 0.830875\n",
            "epoch:[ 811 ], cost: 9.009036287237352 ; loss: 0.14151082839287216; accuracy: 0.83075\n",
            "epoch:[ 812 ], cost: 8.916883767648054 ; loss: 0.14149548612720167; accuracy: 0.83025\n",
            "epoch:[ 813 ], cost: 8.882195170428288 ; loss: 0.14138527142126708; accuracy: 0.831375\n",
            "epoch:[ 814 ], cost: 9.036213777483935 ; loss: 0.14151108270233684; accuracy: 0.8315\n",
            "epoch:[ 815 ], cost: 8.861461347040331 ; loss: 0.14214516016351433; accuracy: 0.831625\n",
            "epoch:[ 816 ], cost: 8.967989085995397 ; loss: 0.14122484510580405; accuracy: 0.830125\n",
            "epoch:[ 817 ], cost: 9.075833262171116 ; loss: 0.1415565590965567; accuracy: 0.830875\n",
            "epoch:[ 818 ], cost: 8.755667946211974 ; loss: 0.142498099112632; accuracy: 0.830125\n",
            "epoch:[ 819 ], cost: 8.940798613053786 ; loss: 0.1413725160097033; accuracy: 0.831625\n",
            "epoch:[ 820 ], cost: 8.996780219151576 ; loss: 0.14134962959598485; accuracy: 0.831\n",
            "epoch:[ 821 ], cost: 8.963104911934973 ; loss: 0.1411059451156146; accuracy: 0.830375\n",
            "epoch:[ 822 ], cost: 8.986301515650089 ; loss: 0.1410734756716136; accuracy: 0.83125\n",
            "epoch:[ 823 ], cost: 8.961007781648428 ; loss: 0.14120512632462118; accuracy: 0.830625\n",
            "epoch:[ 824 ], cost: 8.919036270136072 ; loss: 0.14141255592036844; accuracy: 0.832125\n",
            "epoch:[ 825 ], cost: 9.129623414407908 ; loss: 0.14195171886860192; accuracy: 0.83075\n",
            "epoch:[ 826 ], cost: 8.742426106820927 ; loss: 0.14219963382515624; accuracy: 0.83\n",
            "epoch:[ 827 ], cost: 8.961707021169 ; loss: 0.1418436367588714; accuracy: 0.830625\n",
            "epoch:[ 828 ], cost: 8.915621978182223 ; loss: 0.1421787256079752; accuracy: 0.828875\n",
            "epoch:[ 829 ], cost: 8.802553113057604 ; loss: 0.14222441039351957; accuracy: 0.830875\n",
            "epoch:[ 830 ], cost: 8.984653326687143 ; loss: 0.1416951940533547; accuracy: 0.83075\n",
            "epoch:[ 831 ], cost: 9.028734295666444 ; loss: 0.14240382847876826; accuracy: 0.829625\n",
            "epoch:[ 832 ], cost: 8.86427283366552 ; loss: 0.14211000578894664; accuracy: 0.83025\n",
            "epoch:[ 833 ], cost: 8.94667417997155 ; loss: 0.14182053119334218; accuracy: 0.830375\n",
            "epoch:[ 834 ], cost: 9.07532237887877 ; loss: 0.14186943917258765; accuracy: 0.83075\n",
            "epoch:[ 835 ], cost: 8.879633368277206 ; loss: 0.14215617249723853; accuracy: 0.82925\n",
            "epoch:[ 836 ], cost: 8.984814914731412 ; loss: 0.14162562945339488; accuracy: 0.83025\n",
            "epoch:[ 837 ], cost: 9.057279395229886 ; loss: 0.14109584172166897; accuracy: 0.8295\n",
            "epoch:[ 838 ], cost: 9.055120410947376 ; loss: 0.14136617070798765; accuracy: 0.828625\n",
            "epoch:[ 839 ], cost: 9.008075279287075 ; loss: 0.1415724277699872; accuracy: 0.830375\n",
            "epoch:[ 840 ], cost: 8.917820677175978 ; loss: 0.14224970480622048; accuracy: 0.83125\n",
            "epoch:[ 841 ], cost: 9.024938821747863 ; loss: 0.14147591509309068; accuracy: 0.83\n",
            "epoch:[ 842 ], cost: 8.985051396523895 ; loss: 0.14190918115720483; accuracy: 0.830875\n",
            "epoch:[ 843 ], cost: 8.893885258460617 ; loss: 0.14193675897705157; accuracy: 0.831125\n",
            "epoch:[ 844 ], cost: 9.078452723360009 ; loss: 0.14129237766195657; accuracy: 0.830625\n",
            "epoch:[ 845 ], cost: 8.888740493138428 ; loss: 0.14199948275047594; accuracy: 0.83\n",
            "epoch:[ 846 ], cost: 9.091364315657753 ; loss: 0.14170181539035312; accuracy: 0.830625\n",
            "epoch:[ 847 ], cost: 8.953107610062188 ; loss: 0.14110251840699242; accuracy: 0.828375\n",
            "epoch:[ 848 ], cost: 8.895459514288289 ; loss: 0.14119961197204542; accuracy: 0.8305\n",
            "epoch:[ 849 ], cost: 9.006114554417046 ; loss: 0.14129245230204815; accuracy: 0.83025\n",
            "epoch:[ 850 ], cost: 8.832524038458782 ; loss: 0.14181782769939372; accuracy: 0.83\n",
            "epoch:[ 851 ], cost: 9.027674079807117 ; loss: 0.14164477542013088; accuracy: 0.83075\n",
            "epoch:[ 852 ], cost: 8.729267081080332 ; loss: 0.14300093043454126; accuracy: 0.83\n",
            "epoch:[ 853 ], cost: 8.971406797523086 ; loss: 0.14198023794463713; accuracy: 0.831\n",
            "epoch:[ 854 ], cost: 8.986616696510985 ; loss: 0.14153919274200422; accuracy: 0.828875\n",
            "epoch:[ 855 ], cost: 8.826415465981277 ; loss: 0.1421620613745854; accuracy: 0.829625\n",
            "epoch:[ 856 ], cost: 9.08103197093785 ; loss: 0.14216741406827021; accuracy: 0.831125\n",
            "epoch:[ 857 ], cost: 8.782024577906354 ; loss: 0.14254875210638732; accuracy: 0.829375\n",
            "epoch:[ 858 ], cost: 8.871477375656863 ; loss: 0.14204139891163847; accuracy: 0.830875\n",
            "epoch:[ 859 ], cost: 9.034789325967994 ; loss: 0.14208087389687102; accuracy: 0.82975\n",
            "epoch:[ 860 ], cost: 8.871221218164573 ; loss: 0.14141641393598728; accuracy: 0.8285\n",
            "epoch:[ 861 ], cost: 8.960148340660442 ; loss: 0.14102700204758709; accuracy: 0.830125\n",
            "epoch:[ 862 ], cost: 8.824250562010212 ; loss: 0.14270190718048573; accuracy: 0.8305\n",
            "epoch:[ 863 ], cost: 8.970279181236304 ; loss: 0.14191185018370497; accuracy: 0.8315\n",
            "epoch:[ 864 ], cost: 8.862752632219241 ; loss: 0.14135612881943788; accuracy: 0.83025\n",
            "epoch:[ 865 ], cost: 9.072953405329748 ; loss: 0.1416605424321887; accuracy: 0.830875\n",
            "epoch:[ 866 ], cost: 8.845645068425787 ; loss: 0.14150064649112426; accuracy: 0.82975\n",
            "epoch:[ 867 ], cost: 9.001734090197228 ; loss: 0.14107323761163523; accuracy: 0.83\n",
            "epoch:[ 868 ], cost: 8.793049278188688 ; loss: 0.14269422333919743; accuracy: 0.8305\n",
            "epoch:[ 869 ], cost: 9.001040908878828 ; loss: 0.1411442016140921; accuracy: 0.83125\n",
            "epoch:[ 870 ], cost: 8.921401903187947 ; loss: 0.14232642760077877; accuracy: 0.831125\n",
            "epoch:[ 871 ], cost: 8.926212649352495 ; loss: 0.1419566796049595; accuracy: 0.82925\n",
            "epoch:[ 872 ], cost: 8.853657714971758 ; loss: 0.14211180694382247; accuracy: 0.8315\n",
            "epoch:[ 873 ], cost: 8.93112431600346 ; loss: 0.14180771094310818; accuracy: 0.83\n",
            "epoch:[ 874 ], cost: 8.93680592027113 ; loss: 0.1417400728137055; accuracy: 0.831125\n",
            "epoch:[ 875 ], cost: 8.963045051133676 ; loss: 0.14105227639049853; accuracy: 0.829625\n",
            "epoch:[ 876 ], cost: 8.995636692633006 ; loss: 0.14211682563699435; accuracy: 0.831125\n",
            "epoch:[ 877 ], cost: 8.938375750920798 ; loss: 0.14131371061534959; accuracy: 0.8285\n",
            "epoch:[ 878 ], cost: 8.992609576555889 ; loss: 0.14156980102332353; accuracy: 0.831\n",
            "epoch:[ 879 ], cost: 9.017123180329788 ; loss: 0.14169668922257375; accuracy: 0.82925\n",
            "epoch:[ 880 ], cost: 8.760433844179046 ; loss: 0.14261692203533896; accuracy: 0.830125\n",
            "epoch:[ 881 ], cost: 8.935776045093203 ; loss: 0.1411456048606491; accuracy: 0.83\n",
            "epoch:[ 882 ], cost: 9.003376245849653 ; loss: 0.1416840960179631; accuracy: 0.830125\n",
            "epoch:[ 883 ], cost: 8.919225434349496 ; loss: 0.1414656425338095; accuracy: 0.829625\n",
            "epoch:[ 884 ], cost: 8.884156915934417 ; loss: 0.14215926885189764; accuracy: 0.83175\n",
            "epoch:[ 885 ], cost: 8.939798832516715 ; loss: 0.14127582710325134; accuracy: 0.82875\n",
            "epoch:[ 886 ], cost: 8.808056717938435 ; loss: 0.1417690011066664; accuracy: 0.831\n",
            "epoch:[ 887 ], cost: 9.046768807454901 ; loss: 0.14155963795557747; accuracy: 0.830375\n",
            "epoch:[ 888 ], cost: 8.903652671785567 ; loss: 0.14151203369348064; accuracy: 0.82875\n",
            "epoch:[ 889 ], cost: 8.817449329947381 ; loss: 0.1424474167705259; accuracy: 0.829625\n",
            "epoch:[ 890 ], cost: 8.857578584043694 ; loss: 0.14147594485347031; accuracy: 0.832125\n",
            "epoch:[ 891 ], cost: 9.001458372076529 ; loss: 0.1416289046398008; accuracy: 0.830625\n",
            "epoch:[ 892 ], cost: 9.000446871623824 ; loss: 0.14160761498462213; accuracy: 0.83\n",
            "epoch:[ 893 ], cost: 8.864904536548401 ; loss: 0.1413240303980373; accuracy: 0.8305\n",
            "epoch:[ 894 ], cost: 8.981448712746804 ; loss: 0.14105178748066358; accuracy: 0.8305\n",
            "epoch:[ 895 ], cost: 8.834888698125276 ; loss: 0.1423454480682345; accuracy: 0.830375\n",
            "epoch:[ 896 ], cost: 8.956690442522412 ; loss: 0.14128366373831858; accuracy: 0.8325\n",
            "epoch:[ 897 ], cost: 9.052529651872211 ; loss: 0.1419191396255814; accuracy: 0.831\n",
            "epoch:[ 898 ], cost: 8.999858402192253 ; loss: 0.14158083227374674; accuracy: 0.82975\n",
            "epoch:[ 899 ], cost: 8.815850720782889 ; loss: 0.14248255701413015; accuracy: 0.82975\n",
            "epoch:[ 900 ], cost: 8.963906644743568 ; loss: 0.1410559463620829; accuracy: 0.83275\n",
            "epoch:[ 901 ], cost: 8.921501208400327 ; loss: 0.14132395175691184; accuracy: 0.831\n",
            "epoch:[ 902 ], cost: 8.980146217357275 ; loss: 0.1422808280515188; accuracy: 0.830875\n",
            "epoch:[ 903 ], cost: 8.73061572125701 ; loss: 0.14361266474775847; accuracy: 0.831125\n",
            "epoch:[ 904 ], cost: 8.894365575458878 ; loss: 0.1416316645187589; accuracy: 0.828125\n",
            "epoch:[ 905 ], cost: 8.838629614995053 ; loss: 0.14182446865443013; accuracy: 0.83025\n",
            "epoch:[ 906 ], cost: 8.939631055374536 ; loss: 0.1417919521607767; accuracy: 0.83125\n",
            "epoch:[ 907 ], cost: 8.853139083878368 ; loss: 0.14135406902853886; accuracy: 0.829375\n",
            "epoch:[ 908 ], cost: 8.819888171651169 ; loss: 0.14196570363361957; accuracy: 0.831125\n",
            "epoch:[ 909 ], cost: 8.864610574098434 ; loss: 0.14100030985967732; accuracy: 0.831875\n",
            "epoch:[ 910 ], cost: 8.960868542503343 ; loss: 0.14143579797666622; accuracy: 0.831\n",
            "epoch:[ 911 ], cost: 8.620380125628836 ; loss: 0.1436162820465354; accuracy: 0.83\n",
            "epoch:[ 912 ], cost: 8.891228571930991 ; loss: 0.14137881854526324; accuracy: 0.831875\n",
            "epoch:[ 913 ], cost: 8.992909395038092 ; loss: 0.14150030703314379; accuracy: 0.83075\n",
            "epoch:[ 914 ], cost: 8.814586724389288 ; loss: 0.14197379233119378; accuracy: 0.83075\n",
            "epoch:[ 915 ], cost: 8.98088531170916 ; loss: 0.14142402294502218; accuracy: 0.83025\n",
            "epoch:[ 916 ], cost: 8.91555850757876 ; loss: 0.14149828266263179; accuracy: 0.83075\n",
            "epoch:[ 917 ], cost: 9.089846735384977 ; loss: 0.1419415447900874; accuracy: 0.830625\n",
            "epoch:[ 918 ], cost: 8.937187318325073 ; loss: 0.1421159213362815; accuracy: 0.82925\n",
            "epoch:[ 919 ], cost: 8.862595201499737 ; loss: 0.14224727334449636; accuracy: 0.830125\n",
            "epoch:[ 920 ], cost: 8.959759529830375 ; loss: 0.14166014619141742; accuracy: 0.831375\n",
            "epoch:[ 921 ], cost: 8.953332062356257 ; loss: 0.14143918761719335; accuracy: 0.830125\n",
            "epoch:[ 922 ], cost: 8.769482840278695 ; loss: 0.14218407393596733; accuracy: 0.830875\n",
            "epoch:[ 923 ], cost: 8.932352131812527 ; loss: 0.14144760053760305; accuracy: 0.83175\n",
            "epoch:[ 924 ], cost: 8.897124494628889 ; loss: 0.14150065287920674; accuracy: 0.831\n",
            "epoch:[ 925 ], cost: 8.958541366899054 ; loss: 0.1419337057496572; accuracy: 0.829875\n",
            "epoch:[ 926 ], cost: 8.74044405721407 ; loss: 0.14225033395864772; accuracy: 0.830625\n",
            "epoch:[ 927 ], cost: 8.900160377951947 ; loss: 0.14178322673325228; accuracy: 0.830875\n",
            "epoch:[ 928 ], cost: 8.808124333462564 ; loss: 0.14229482243582708; accuracy: 0.83025\n",
            "epoch:[ 929 ], cost: 8.932245919974621 ; loss: 0.14096931878566177; accuracy: 0.831375\n",
            "epoch:[ 930 ], cost: 8.902594096479312 ; loss: 0.14174348305432216; accuracy: 0.8305\n",
            "epoch:[ 931 ], cost: 8.872813625523845 ; loss: 0.14261422563006074; accuracy: 0.8305\n",
            "epoch:[ 932 ], cost: 8.846525279972637 ; loss: 0.14170405063733124; accuracy: 0.8315\n",
            "epoch:[ 933 ], cost: 9.034283403353024 ; loss: 0.14173355092188966; accuracy: 0.8305\n",
            "epoch:[ 934 ], cost: 8.890557653434165 ; loss: 0.14127219564581053; accuracy: 0.830625\n",
            "epoch:[ 935 ], cost: 8.857087071913226 ; loss: 0.1416641256053723; accuracy: 0.830875\n",
            "epoch:[ 936 ], cost: 9.044780823069035 ; loss: 0.1420166254934096; accuracy: 0.831125\n",
            "epoch:[ 937 ], cost: 8.689285329134906 ; loss: 0.14301161728146985; accuracy: 0.830125\n",
            "epoch:[ 938 ], cost: 8.89691052801642 ; loss: 0.14140567386182096; accuracy: 0.8315\n",
            "epoch:[ 939 ], cost: 8.887588897930904 ; loss: 0.1412337370297227; accuracy: 0.830875\n",
            "epoch:[ 940 ], cost: 8.88160216042686 ; loss: 0.14162419735760323; accuracy: 0.83075\n",
            "epoch:[ 941 ], cost: 8.945601653607174 ; loss: 0.14110121737678152; accuracy: 0.83175\n",
            "epoch:[ 942 ], cost: 8.822642991270959 ; loss: 0.1424450000643306; accuracy: 0.83075\n",
            "epoch:[ 943 ], cost: 9.026611040562052 ; loss: 0.14168809669062898; accuracy: 0.831375\n",
            "epoch:[ 944 ], cost: 8.850855792411753 ; loss: 0.14226126676667497; accuracy: 0.829875\n",
            "epoch:[ 945 ], cost: 9.057676250487631 ; loss: 0.1415089812176149; accuracy: 0.831375\n",
            "epoch:[ 946 ], cost: 8.91091235102012 ; loss: 0.14179551028794038; accuracy: 0.829625\n",
            "epoch:[ 947 ], cost: 8.992604286210614 ; loss: 0.14185187504409122; accuracy: 0.83\n",
            "epoch:[ 948 ], cost: 9.022888061566004 ; loss: 0.14100821940259914; accuracy: 0.830375\n",
            "epoch:[ 949 ], cost: 9.016902986783938 ; loss: 0.14102812141266907; accuracy: 0.830125\n",
            "epoch:[ 950 ], cost: 9.049867961429998 ; loss: 0.14178659183601056; accuracy: 0.830625\n",
            "epoch:[ 951 ], cost: 9.04544873614709 ; loss: 0.14202109183296335; accuracy: 0.83\n",
            "epoch:[ 952 ], cost: 8.809746852786738 ; loss: 0.14209618447650615; accuracy: 0.83125\n",
            "epoch:[ 953 ], cost: 8.830694868957346 ; loss: 0.14266354747606896; accuracy: 0.83075\n",
            "epoch:[ 954 ], cost: 8.92483180522366 ; loss: 0.14212688758091288; accuracy: 0.8325\n",
            "epoch:[ 955 ], cost: 8.909711817987072 ; loss: 0.14235984899908383; accuracy: 0.831625\n",
            "epoch:[ 956 ], cost: 9.029121301504112 ; loss: 0.1417364075040612; accuracy: 0.830125\n",
            "epoch:[ 957 ], cost: 8.941004933217144 ; loss: 0.14134473520875399; accuracy: 0.829375\n",
            "epoch:[ 958 ], cost: 9.053450095045271 ; loss: 0.1411908993319581; accuracy: 0.829875\n",
            "epoch:[ 959 ], cost: 8.879907024349926 ; loss: 0.14229382254967; accuracy: 0.83\n",
            "epoch:[ 960 ], cost: 9.090647238169442 ; loss: 0.14171784026156667; accuracy: 0.8315\n",
            "epoch:[ 961 ], cost: 9.044246436009292 ; loss: 0.1414473516327131; accuracy: 0.829125\n",
            "epoch:[ 962 ], cost: 8.96763480996779 ; loss: 0.1410006844923234; accuracy: 0.83075\n",
            "epoch:[ 963 ], cost: 9.042082266786753 ; loss: 0.14113195234714873; accuracy: 0.830875\n",
            "epoch:[ 964 ], cost: 8.828199072290298 ; loss: 0.1428159587589171; accuracy: 0.83075\n",
            "epoch:[ 965 ], cost: 9.084369451077835 ; loss: 0.14187705339630513; accuracy: 0.83075\n",
            "epoch:[ 966 ], cost: 9.054887391110155 ; loss: 0.14134596911721029; accuracy: 0.82925\n",
            "epoch:[ 967 ], cost: 8.81595848396171 ; loss: 0.14260967713050082; accuracy: 0.831125\n",
            "epoch:[ 968 ], cost: 9.04803530663587 ; loss: 0.14152969435824905; accuracy: 0.831125\n",
            "epoch:[ 969 ], cost: 8.977870240266022 ; loss: 0.1417574794986296; accuracy: 0.831125\n",
            "epoch:[ 970 ], cost: 8.961008935984166 ; loss: 0.14175757402294567; accuracy: 0.830625\n",
            "epoch:[ 971 ], cost: 8.97402321268573 ; loss: 0.14139478488646826; accuracy: 0.83025\n",
            "epoch:[ 972 ], cost: 9.0523906719742 ; loss: 0.14222030442533581; accuracy: 0.8305\n",
            "epoch:[ 973 ], cost: 8.699211747551882 ; loss: 0.14277455027906108; accuracy: 0.830875\n",
            "epoch:[ 974 ], cost: 8.888993096443345 ; loss: 0.14216501664197925; accuracy: 0.83025\n",
            "epoch:[ 975 ], cost: 9.070440159099418 ; loss: 0.14184758768254; accuracy: 0.831125\n",
            "epoch:[ 976 ], cost: 8.903280349547936 ; loss: 0.14163570113323287; accuracy: 0.829625\n",
            "epoch:[ 977 ], cost: 9.053658487064638 ; loss: 0.14205345097644237; accuracy: 0.831\n",
            "epoch:[ 978 ], cost: 8.810668674660977 ; loss: 0.14218842572302454; accuracy: 0.829625\n",
            "epoch:[ 979 ], cost: 8.90240152795399 ; loss: 0.1419992164899599; accuracy: 0.829625\n",
            "epoch:[ 980 ], cost: 9.055427690951536 ; loss: 0.1414840153353; accuracy: 0.831875\n",
            "epoch:[ 981 ], cost: 8.829553911399554 ; loss: 0.142404317267205; accuracy: 0.8305\n",
            "epoch:[ 982 ], cost: 9.086734879733623 ; loss: 0.14159558013405096; accuracy: 0.831125\n",
            "epoch:[ 983 ], cost: 8.882091387817884 ; loss: 0.1419726074926649; accuracy: 0.830125\n",
            "epoch:[ 984 ], cost: 9.068452658057861 ; loss: 0.1415310476499432; accuracy: 0.83075\n",
            "epoch:[ 985 ], cost: 8.919645597001136 ; loss: 0.14173270536026228; accuracy: 0.830375\n",
            "epoch:[ 986 ], cost: 9.021927517023343 ; loss: 0.14125342843499727; accuracy: 0.8295\n",
            "epoch:[ 987 ], cost: 8.921672445713854 ; loss: 0.14166798644145154; accuracy: 0.831125\n",
            "epoch:[ 988 ], cost: 9.019236051052648 ; loss: 0.14165437667118638; accuracy: 0.8305\n",
            "epoch:[ 989 ], cost: 8.983788503240476 ; loss: 0.1417586494092635; accuracy: 0.832\n",
            "epoch:[ 990 ], cost: 9.06174206242381 ; loss: 0.14119800944797725; accuracy: 0.830125\n",
            "epoch:[ 991 ], cost: 8.928617384806257 ; loss: 0.14181576444685606; accuracy: 0.831\n",
            "epoch:[ 992 ], cost: 9.139571442225572 ; loss: 0.14175746055102986; accuracy: 0.831625\n",
            "epoch:[ 993 ], cost: 8.881207387962396 ; loss: 0.1420611893113531; accuracy: 0.830125\n",
            "epoch:[ 994 ], cost: 9.122077174904849 ; loss: 0.14143968670356383; accuracy: 0.83\n",
            "epoch:[ 995 ], cost: 8.930483031887825 ; loss: 0.14165704938160678; accuracy: 0.83\n",
            "epoch:[ 996 ], cost: 9.079197655958215 ; loss: 0.1415752463333942; accuracy: 0.82975\n",
            "epoch:[ 997 ], cost: 9.013364641093517 ; loss: 0.14173182782854; accuracy: 0.830875\n",
            "epoch:[ 998 ], cost: 9.049121987605696 ; loss: 0.14118672955423647; accuracy: 0.83\n",
            "epoch:[ 999 ], cost: 8.987638687559306 ; loss: 0.14111507120000033; accuracy: 0.830125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-8hMDyzQZqm",
        "colab_type": "code",
        "outputId": "926685d9-b63a-40e0-e9a5-cb08c817ea2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "plotCost(NN.get_cost_histroy(), epoch )\n",
        "plotAccuracy(NN.get_accuracy_histroy(), epoch )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAGDCAYAAABjkcdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGDCAYAAAB0s1eWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/uFTyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6ROChOed9pC",
        "colab_type": "code",
        "outputId": "f0ebff1a-f2bc-4644-dbc6-fc7348ae64b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "y_pred = NN.predict(X_test)\n",
        "y_pred = (y_pred >= 0.5)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[1541   54]\n",
            " [ 260  145]]\n",
            "\n",
            "Accuracy Score: 0.843\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91      1595\n",
            "           1       0.73      0.36      0.48       405\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.79      0.66      0.69      2000\n",
            "weighted avg       0.83      0.84      0.82      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}