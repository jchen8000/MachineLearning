{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generative_adversarial_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/MachineLearning/blob/master/10%20Generative%20Adversarial%20Network/generative_adversarial_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iniBQOhgJjN1",
        "colab_type": "text"
      },
      "source": [
        "# Generative Adversarial Network(GAN)\n",
        "\n",
        "***ABSTRACT***\n",
        "\n",
        "This is a hands-on practice of using Keras and Tensorflow to build and train a Generative Adversarial Network(GAN) against MNIST dataset which has handwritten digit black/white images with 28x28 pixels. This dataset is widely known for for machine learning purpose. We first load the dataset from Keras library and pre-process it. Then we build a Generator and a Discriminator, we also build a GAN which connect the Generator with the Discriminator. We take 10 digit image from the MNIST handwritten dataset as ground truth sample to train our GAN. We create a random noise vector with Gaussian distribution and feed it to the Generator to create a number of generated images and label them as 0, we also use the ground truth images and label them as 1, we use these images to feed to  Discriminator and train it. After the Discriminator is trained, we again create random noise and label them as 1 to fool the Discriminator, and train the GAN with Discriminator frozen, the purpose of this is to train the Generator and fool the Discriminator to make it think the generated image are real. We run these steps repeatly until a number of epoches, during running we visulize the generated images which give an animated effect to show how the generated images are improved as the training process is going.\n",
        "\n",
        "\n",
        "\n",
        "10 Generative Adversarial Network/generative_adversarial_network.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRD6BPa9Ja1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.models import Model,Sequential\n",
        "from keras.datasets import mnist\n",
        "from tqdm import tqdm\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axf5ZxOuJqlh",
        "colab_type": "text"
      },
      "source": [
        "## 1. MNIST Dataset\n",
        "\n",
        "The MNIST database is a well known dataset that contains thousands of handwritten digits for machine learning purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPozZVsCJvBE",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Load MNIST dataset from tensorflow library\n",
        "\n",
        "When we load the dataset below, X_train and X_test will contain the images, and y_train and y_test will contain the digits that those images represent.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiHVrjqlJ3uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "#print(\"X_train\", X_train.shape)\n",
        "#print(\"y_train\", y_train.shape)\n",
        "#print(\"X_test\", X_test.shape)\n",
        "#print(\"y_test\", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIEUq_zRKC5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
        "\n",
        "    \n",
        "    # convert shape of x_train from (60000, 28, 28) to (60000, 784) \n",
        "    # 784 columns per row\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    return (x_train, y_train, x_test, y_test)\n",
        "  \n",
        "(X_train, y_train,X_test, y_test)=load_data()\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWSRRSlKKGoP",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Pre-process the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHf5irh1KL34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train = X_train.astype(np.float32).reshape(X_train.shape[0], height, width, channels)\n",
        "#X_test = X_test.astype(np.float32).reshape(X_test.shape[0], height, width, channels)\n",
        "#input_shape = (height, width, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NV7x94NKSaW",
        "colab_type": "text"
      },
      "source": [
        "## 2. Build Generative Adversarial Network(GAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn6E8TJVKezg",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Build a Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKkb6bMzKj6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adam_optimizer():\n",
        "    return Adam(lr=0.0002, beta_1=0.5)\n",
        "  \n",
        "def create_generator():\n",
        "    generator=Sequential()\n",
        "    generator.add(Dense(units=256,input_dim=100))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(Dense(units=512))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(Dense(units=1024))\n",
        "    generator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    generator.add(Dense(units=784, activation='tanh'))\n",
        "    \n",
        "    generator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
        "    return generator\n",
        "  \n",
        "theGenerator = create_generator()\n",
        "theGenerator.summary()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYBcrvv8KsRA",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Build a Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHkL_xjtKxdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_discriminator():\n",
        "    discriminator=Sequential()\n",
        "    discriminator.add(Dense(units=1024,input_dim=784))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "       \n",
        "    \n",
        "    discriminator.add(Dense(units=512))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    discriminator.add(Dropout(0.3))\n",
        "       \n",
        "    discriminator.add(Dense(units=256))\n",
        "    discriminator.add(LeakyReLU(0.2))\n",
        "    \n",
        "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
        "    \n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
        "    return discriminator\n",
        "  \n",
        "theDiscriminator = create_discriminator()\n",
        "theDiscriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sByDeiiQK134",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Build the GAN by connecting the Generator and Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nMcnuZKK6Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_gan(discriminator, generator):\n",
        "    discriminator.trainable=False\n",
        "    gan_input = Input(shape=(100,))\n",
        "    x = generator(gan_input)\n",
        "    gan_output= discriminator(x)\n",
        "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
        "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return gan\n",
        "  \n",
        "theGan = create_gan(theDiscriminator, theGenerator)\n",
        "theGan.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEdSSATxMpT0",
        "colab_type": "text"
      },
      "source": [
        "## 3. Training the GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps4_cNpYMtk2",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Visualize the original images and generated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPP-iMCBM3CH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG, display\n",
        "from PIL import Image\n",
        "\n",
        "def invert_image(img):\n",
        "    return( np.invert(img)  )\n",
        "\n",
        "  \n",
        "def denomalize_image(img, invert=False):\n",
        "    if img.dtype is np.dtype(np.float32):\n",
        "      image = img * 255\n",
        "      image = image.astype('uint8')\n",
        "    else:\n",
        "      image = img\n",
        "    \n",
        "    if invert == True:\n",
        "      image = invert_image( image )\n",
        "\n",
        "    return( image )\n",
        "    \n",
        "\n",
        "def init_display(img, zoom=1):\n",
        "    height, width = img.shape\n",
        "    img_array=denomalize_image(img, invert=True)\n",
        "    img_disp = Image.fromarray(img_array,mode='P')\n",
        "    if zoom == 1:\n",
        "      out = display(img_disp, display_id=True)\n",
        "    else:\n",
        "      out = display(img_disp.resize((width*zoom,height*zoom)), display_id=True)\n",
        "    return( out )\n",
        "\n",
        "\n",
        "def update_display(out, img, zoom=1):\n",
        "    height, width = img.shape\n",
        "    img_array=denomalize_image(img, invert=True)\n",
        "    img_disp = Image.fromarray(img_array,mode='P')\n",
        "    if zoom == 1:\n",
        "      out.update(img_disp)\n",
        "    else:\n",
        "      out.update(img_disp.resize((width*zoom,height*zoom)))\n",
        "\n",
        "\n",
        "      \n",
        "def plot_output( epoch, generator, examples=16, initial=False, out=None ):\n",
        "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples,28,28)\n",
        "    plot_image = np.concatenate(generated_images, axis = 1)\n",
        "    if initial == False:\n",
        "      update_display(out, plot_image)\n",
        "    else:\n",
        "      output = init_display(plot_image)\n",
        "      return( output )\n",
        "    \n",
        "\n",
        "def plot_sample( sample ):\n",
        "    plot_image = np.concatenate(sample.reshape(sample.shape[0],28,28), axis = 1)\n",
        "    output = init_display(plot_image)\n",
        "    return( output )\n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joiU_bBbM6g0",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Train the GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ9ujYhJM_EP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "batch_size = 64\n",
        "sample_size = 10\n",
        "\n",
        "#Pick the sample images -- each one from number 0 to 9\n",
        "sample = np.empty(shape=sample_size).astype('uint8')\n",
        "for i in range(0,sample_size):\n",
        "  sample[i] = np.where(y_train==i)[0][1]\n",
        "\n",
        "#Show the sample images\n",
        "sample_image = X_train[sample]\n",
        "plot_sample( sample_image )\n",
        "\n",
        "\n",
        "#Display the initial generator generated images\n",
        "display_output = plot_output( 0, theGenerator, examples=16, initial=True )\n",
        "\n",
        "\n",
        "#\n",
        "# Main loop for training the GAN\n",
        "#\n",
        "for e in range(1,epochs+1 ):\n",
        "\n",
        "    pbar = tqdm(range(batch_size))\n",
        "    for _ in pbar:\n",
        "      \n",
        "        pbar.set_description(\"Epoch %d\" % e)      \n",
        "      \n",
        "        #generate random noise as an input to initialize the generator\n",
        "        noise= np.random.normal(0,1, [batch_size, 100])\n",
        "        generated_images = theGenerator.predict(noise)\n",
        "\n",
        "        # Make the ground truth images from the sample images, \n",
        "        # randomly create them by the number of batch_size \n",
        "        #image_batch = X_train[np.random.choice(sample, size=batch_size)]\n",
        "        image_batch = sample_image\n",
        "\n",
        "        #Mix the ground truth images with the generated images,\n",
        "        #and label them 1 for ground truth and 0 for generated ones\n",
        "        X_gan = np.concatenate([image_batch, generated_images])\n",
        "        y_gan = np.concatenate([np.ones(image_batch.shape[0]), np.zeros(generated_images.shape[0])])\n",
        "        y_gan = y_gan.astype(np.float32)\n",
        "\n",
        "        #First train the discriminator. \n",
        "        theDiscriminator.trainable=True\n",
        "        theDiscriminator.train_on_batch(X_gan, y_gan)\n",
        "\n",
        "        #Tricking the noised input of the Generator as real data\n",
        "        noise= np.random.normal(0,1, [batch_size, 100])\n",
        "        y_gen = np.ones(batch_size)\n",
        "\n",
        "        # During the training of gan, \n",
        "        # the weights of discriminator should be fixed. \n",
        "        #We can enforce that by setting the trainable flag\n",
        "        theDiscriminator.trainable=False\n",
        "\n",
        "        #training  the GAN by alternating the training of the Discriminator \n",
        "        #and training the chained GAN model with Discriminator’s weights freezed.\n",
        "        theGan.train_on_batch(noise, y_gen)\n",
        "\n",
        "    if e == 1 or e % 2 == 0:\n",
        "        #plot_generated_images(e, generator)\n",
        "        plot_output( e, theGenerator, out=display_output )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUxRe4hYNDiQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Display the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqMfhb56NGfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_sample( sample_image )\n",
        "\n",
        "for i in range(16):\n",
        "  plot_output( 0, theGenerator, examples=16, initial=True )\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjaqjzISNNAX",
        "colab_type": "text"
      },
      "source": [
        "## 4. Save the model to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfH4vTMTNTe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU3_f1lkNXDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GDrivePath = F\"/content/gdrive/'My Drive'/MachineLearning/'10 Generative Adversarial Network'\" \n",
        "\n",
        "theGan.save('theGan.h5')\n",
        "theDiscriminator.save('theDiscriminator.h5')\n",
        "theGenerator.save('theGenerator.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKGxqU2nNZXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp *.h5 $GDrivePath\n",
        "!ls $GDrivePath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_nzD0tENdYX",
        "colab_type": "text"
      },
      "source": [
        "## 5. Others, for testing purpose\n",
        "\n",
        "\n",
        "Reference:\n",
        "* https://medium.com/datadriveninvestor/generative-adversarial-network-gan-using-keras-ce1c05cfdfd3\n",
        "* https://blog.insightdatascience.com/generating-custom-photo-realistic-faces-using-ai-d170b1b59255\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yoM8gGtNg-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pick the sample images\n",
        "for j in range(0,10):\n",
        "  sample = np.empty(shape=10).astype('uint8')\n",
        "  for i in range(0,10):\n",
        "    sample[i] = np.where(y_train==i)[0][j]\n",
        "\n",
        "  image_batch = X_train[sample]\n",
        "  plot_sample( image_batch )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jVigmjWNj-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_sample( X_gan[0:20,:] )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}