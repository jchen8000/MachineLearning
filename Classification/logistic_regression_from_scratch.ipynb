{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression_from_scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jchen8000/MachineLearning/blob/master/Classification/logistic_regression_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "d29hm6cwYWuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression From Scratch"
      ]
    },
    {
      "metadata": {
        "id": "qqzWioayYmzg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "BeHy__8qYEkQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from IPython.display import Math, HTML\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXQRk7A3YqLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Importing the dataset"
      ]
    },
    {
      "metadata": {
        "id": "fKLcJXOVYinO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for some reasons, the data file on github has some problems when reading\n",
        "#datafile = 'https://github.com/jchen8000/MachineLearning/blob/master/Classification/data/Churn_Modelling.csv'\n",
        "\n",
        "#Found the same data file from internet\n",
        "datafile = 'https://floobits.com/calvinlow18/ANN/raw/Churn_Modelling.csv'\n",
        "dataset = pd.read_csv(datafile)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D2ImbpCCYtvt",
        "colab_type": "code",
        "outputId": "22d0586a-68a2-452d-c07b-19e62b247698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "XieTbrpKZkPH",
        "colab_type": "code",
        "outputId": "1c0f4526-15c4-45d8-bb3b-65aaedf3da91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r1tDX_zFZo2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Encoding categorical data"
      ]
    },
    {
      "metadata": {
        "id": "YvA5EuVwZt4C",
        "colab_type": "code",
        "outputId": "48ce61b6-1e6b-4caa-8ede-96f847704aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
        "X = onehotencoder.fit_transform(X).toarray()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QHn9grSVaY9x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 Feature Scaling"
      ]
    },
    {
      "metadata": {
        "id": "WCMDl-4SacTo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_Nga4sJszbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 Add Bias vector"
      ]
    },
    {
      "metadata": {
        "id": "5JkJtm3rrgiK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d2158737-40fe-42fd-c5f9-d90a7fa3a79d"
      },
      "cell_type": "code",
      "source": [
        "print(\"Before bias vector added:\", X.shape)\n",
        "m = X.shape[0]\n",
        "X = np.hstack((np.ones((m,1)), X))\n",
        "print(\"After add bias vector\", X.shape)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before bias vector added: (10000, 12)\n",
            "After add bias vector (10000, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NByg1h3laQW3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "metadata": {
        "id": "b6OBd_kgaUKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7dc88329-afd9-4def-b057-e6288f354f95"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_test: \", y_test.shape)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:  (8000, 13)\n",
            "X_test:  (2000, 13)\n",
            "y_train:  (8000,)\n",
            "y_test:  (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2T-CbucLakB2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Logistic Regression "
      ]
    },
    {
      "metadata": {
        "id": "eNvpHT6gbQZp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 Sigmoid function, Cost Function and Gradient\n",
        "\n",
        "**2.1.1 Sigmoid function**\n",
        "\n",
        "> # $h_ \\theta (x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^- \\theta^Tx }  $\n",
        "\n",
        "> The sigmoid function is having a characteristic \"S\"-shaped curve or ***sigmoid curve***, as  below\n",
        "\n",
        "> ![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png)"
      ]
    },
    {
      "metadata": {
        "id": "2iQFwek1SO3J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.1.2 Regularized Cost Function for Logistic Regression **\n",
        "\n",
        "> The Regularized cost function for logistic regression is:\n",
        "\n",
        ">## $J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}[-y^{(i)}log(h_{\\theta}(x^{(i)})) - (1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GPtz7S5XSnXk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.1.3 Regularized Gradient Descent for Logistic Regression**\n",
        "\n",
        ">  for j = 0:\n",
        "\n",
        ">> ## $\\frac{\\partial J(\\theta)}{\\partial \\theta_{0}} = \\frac{1}{m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$\n",
        "\n",
        "> for j >= 1:\n",
        "\n",
        ">> ## $\\frac{\\partial J(\\theta)}{\\partial \\theta_{j}} = \\Big(\\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}\\Big) + \\frac{\\lambda}{m} \\theta_{j} $\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XoVJk17Eb_93",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "\n",
        "def costFunction(theta_t, X_t, y_t, lambda_t):\n",
        "    m = len(y_t)\n",
        "    J = (-1/m) * (y_t.T @ np.log(sigmoid(X_t @ theta_t)) + (1 - y_t.T) @ np.log(1 - sigmoid(X_t @ theta_t)))\n",
        "    reg = (lambda_t/(2*m)) * (theta_t[1:].T @ theta_t[1:])\n",
        "    J = J + reg\n",
        "    return J\n",
        "  \n",
        "\n",
        "def GradientDescent(theta, X, y, lambda_t):\n",
        "    m = len(y)\n",
        "    grad = np.zeros([m,1])\n",
        "    grad = (1/m) * X.T @ (sigmoid(X @ theta) - y)\n",
        "    grad[1:] = grad[1:] + (lambda_t / m) * theta[1:]\n",
        "    return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MqG4Ah2zcHig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Learning parameters using fmin_tnc"
      ]
    },
    {
      "metadata": {
        "id": "JG10VBaMbPPX",
        "colab_type": "code",
        "outputId": "f6fada0e-0759-4ba4-9403-fd00e9588b3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "(m, n) = X_train.shape\n",
        "y_train = y_train[:, np.newaxis]\n",
        "theta = np.zeros((n,1))\n",
        "lmbda = 1\n",
        "J = costFunction(theta, X_train, y_train, lmbda)\n",
        "print(J)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.69314718]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "odNCxS_ZcGCF",
        "colab_type": "code",
        "outputId": "96076aa2-b59d-4c18-9453-a8367a3a4788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "import scipy.optimize as opt  \n",
        "iteration = 50\n",
        "\n",
        "\n",
        "theta = opt.fmin_cg(f = costFunction, x0 = theta.flatten(),  fprime = GradientDescent, args = (X_train, y_train.flatten(), lmbda), maxiter = iteration)\n",
        "\n",
        "#output = opt.fmin_tnc(func = costFunction, x0 = theta.flatten(), fprime = GradientDescent, \\\n",
        "#                         args = (X_train, y_train.flatten(), lmbda), maxiter = iteration)\n",
        "#theta = output[0]\n",
        "print(theta) # theta contains the optimized values"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.429069\n",
            "         Iterations: 8\n",
            "         Function evaluations: 19\n",
            "         Gradient evaluations: 19\n",
            "[-1.63685723 -0.14136409  0.23636897 -0.07364662 -0.07208391 -0.26918615\n",
            "  0.75457167 -0.08137458  0.15306213 -0.085331   -0.02370001 -0.51819785\n",
            "  0.02916427]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pTVQDvwHhETK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The final costs**"
      ]
    },
    {
      "metadata": {
        "id": "LdK2lI9JfQi0",
        "colab_type": "code",
        "outputId": "bf6c8202-be20-4319-bacc-b995be57d749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "J = costFunction(theta, X_train, y_train, lmbda)\n",
        "print(J)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.42906934]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FH97YJZbc0oQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3 Evaluating logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "InT1gTAldikC",
        "colab_type": "code",
        "outputId": "00cb7832-a6a8-4417-aba8-dfd18b71d1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = sigmoid(np.dot(X_test, theta))\n",
        "y_pred = (y_pred >= 0.5)\n",
        "y_pred.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "metadata": {
        "id": "rmPpTUPrdDSs",
        "colab_type": "code",
        "outputId": "77bba6fd-7add-4abe-d719-8cb638ff5381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[1526   69]\n",
            " [ 309   96]]\n",
            "\n",
            "Accuracy Score: 0.811\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.96      0.89      1595\n",
            "           1       0.58      0.24      0.34       405\n",
            "\n",
            "   micro avg       0.81      0.81      0.81      2000\n",
            "   macro avg       0.71      0.60      0.61      2000\n",
            "weighted avg       0.78      0.81      0.78      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}