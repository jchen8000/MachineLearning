{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jchen8000/MachineLearning/blob/master/Classification/logistic_regression_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d29hm6cwYWuY"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqzWioayYmzg"
   },
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BeHy__8qYEkQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXQRk7A3YqLe"
   },
   "source": [
    "### 1.1 Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKLcJXOVYinO"
   },
   "outputs": [],
   "source": [
    "#for some reasons, the data file on github has some problems when reading\n",
    "#datafile = 'https://github.com/jchen8000/MachineLearning/blob/master/Classification/data/Churn_Modelling.csv'\n",
    "\n",
    "#Found the same data file from internet\n",
    "datafile = 'https://floobits.com/calvinlow18/ANN/raw/Churn_Modelling.csv'\n",
    "dataset = pd.read_csv(datafile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "D2ImbpCCYtvt",
    "outputId": "ff1f2b53-0326-424f-af7e-4afe396beef3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XieTbrpKZkPH",
    "outputId": "a797fd36-8588-4940-b4c1-430c4d83a976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r1tDX_zFZo2H"
   },
   "source": [
    "### 1.2 Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "YvA5EuVwZt4C",
    "outputId": "ad93bb8f-328b-45fc-bc8f-11a180f75889"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHn9grSVaY9x"
   },
   "source": [
    "### 1.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCMDl-4SacTo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_Nga4sJszbb"
   },
   "source": [
    "### 1.4 Add Bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5JkJtm3rrgiK",
    "outputId": "a0fe1782-3b1e-4df6-a19f-5cee5044e024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before bias vector added: (10000, 12)\n",
      "After add bias vector (10000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before bias vector added:\", X.shape)\n",
    "m = X.shape[0]\n",
    "X = np.hstack((np.ones((m,1)), X))\n",
    "print(\"After add bias vector\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NByg1h3laQW3"
   },
   "source": [
    "### 1.5 Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "b6OBd_kgaUKq",
    "outputId": "b2f79682-274e-45d4-b1af-58b85589b8f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (8000, 13)\n",
      "X_test:  (2000, 13)\n",
      "y_train:  (8000,)\n",
      "y_test:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2T-CbucLakB2"
   },
   "source": [
    "## 2. Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNvpHT6gbQZp"
   },
   "source": [
    "### 2.1 Sigmoid function, Cost Function and Gradient Descent\n",
    "\n",
    "\n",
    "\n",
    "**2.1.1 Sigmoid function**\n",
    "\n",
    "> # $h_ \\theta (x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{- \\theta^Tx} }  $\n",
    "\n",
    "> The sigmoid function is having a characteristic \"S\"-shaped curve or ***sigmoid curve***, as  below\n",
    "\n",
    "> ![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/480px-Logistic-curve.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "e8NmS7Owegph",
    "outputId": "d6c5fcd6-f35a-45af-fb39-c1f0c0b1605e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nimG2IdL2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "\n",
    "axis_x = np.arange(-10,10,.1)\n",
    "plt.plot(axis_x,sigmoid(axis_x))\n",
    "plt.title(\"Sigmoid Function.\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iQFwek1SO3J"
   },
   "source": [
    "**2.1.2 Regularized Cost Function for Logistic Regression **\n",
    "\n",
    "> The Regularized cost function for logistic regression is:\n",
    "\n",
    ">## $J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m}[-y^{(i)}log(h_{\\theta}(x^{(i)})) - (1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_{j}^{2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPtz7S5XSnXk"
   },
   "source": [
    "**2.1.3 Regularized Gradient Descent for Logistic Regression**\n",
    "\n",
    ">  for j = 0:\n",
    "\n",
    ">> ## $\\frac{\\partial J(\\theta)}{\\partial \\theta_{0}} = \\frac{1}{m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)}) - y^{(i)})x_{j}^{(i)}$\n",
    "\n",
    "> for j >= 1:\n",
    "\n",
    ">> ## $\\frac{\\partial J(\\theta)}{\\partial \\theta_{j}} = \\Big(\\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}\\Big) + \\frac{\\lambda}{m} \\theta_{j} $\n",
    "\n",
    "> The following code implements the above math expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoVJk17Eb_93"
   },
   "outputs": [],
   "source": [
    "\n",
    "def costFunction(theta_t, X_t, y_t, lambda_t):\n",
    "    m = len(y_t)\n",
    "    J = (-1/m) * (y_t.T @ np.log(sigmoid(X_t @ theta_t)) + (1 - y_t.T) @ np.log(1 - sigmoid(X_t @ theta_t)))\n",
    "    reg = (lambda_t/(2*m)) * (theta_t[1:].T @ theta_t[1:])\n",
    "    J = J + reg\n",
    "    return J\n",
    "  \n",
    "\n",
    "def GradientDescent(theta, X, y, lambda_t):\n",
    "    m = len(y)\n",
    "    grad = np.zeros([m,1])\n",
    "    grad = (1/m) * X.T @ (sigmoid(X @ theta) - y)\n",
    "    grad[1:] = grad[1:] + (lambda_t / m) * theta[1:]\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqG4Ah2zcHig"
   },
   "source": [
    "### 2.2 Learning parameters using fmin_tnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JG10VBaMbPPX",
    "outputId": "43b1a924-6558-4b38-f45e-2fca894dc166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69314718]]\n"
     ]
    }
   ],
   "source": [
    "(m, n) = X_train.shape\n",
    "#y_train = y_train[:, np.newaxis]\n",
    "theta = np.zeros((n,1))\n",
    "lmbda = 1\n",
    "J = costFunction(theta, X_train, y_train, lmbda)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "odNCxS_ZcGCF",
    "outputId": "1ceb27f3-95ee-4efa-fc57-774169707c2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.429069\n",
      "         Iterations: 8\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 19\n",
      "[-1.63685723 -0.14136409  0.23636897 -0.07364662 -0.07208391 -0.26918615\n",
      "  0.75457167 -0.08137458  0.15306213 -0.085331   -0.02370001 -0.51819785\n",
      "  0.02916427]\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt  \n",
    "iteration = 50\n",
    "\n",
    "\n",
    "theta = opt.fmin_cg(f = costFunction, x0 = theta.flatten(),  fprime = GradientDescent, args = (X_train, y_train.flatten(), lmbda), maxiter = iteration)\n",
    "\n",
    "#output = opt.fmin_tnc(func = costFunction, x0 = theta.flatten(), fprime = GradientDescent, \\\n",
    "#                         args = (X_train, y_train.flatten(), lmbda), maxiter = iteration)\n",
    "#theta = output[0]\n",
    "print(theta) # theta contains the optimized values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTVQDvwHhETK"
   },
   "source": [
    "**The final costs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LdK2lI9JfQi0",
    "outputId": "584e42da-e8fc-4e1f-bfe6-462edde00c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42906933690751703\n"
     ]
    }
   ],
   "source": [
    "J = costFunction(theta, X_train, y_train, lmbda)\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FH97YJZbc0oQ"
   },
   "source": [
    "### 2.3 Evaluating logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "InT1gTAldikC",
    "outputId": "07adb075-3518-4ed3-a443-b10623917141"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sigmoid(np.dot(X_test, theta))\n",
    "y_pred = (y_pred >= 0.5)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "rmPpTUPrdDSs",
    "outputId": "816bef70-f5c7-453d-b3fe-768809818cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1526   69]\n",
      " [ 309   96]]\n",
      "\n",
      "Accuracy Score: 0.811\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1595\n",
      "           1       0.58      0.24      0.34       405\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2000\n",
      "   macro avg       0.71      0.60      0.61      2000\n",
      "weighted avg       0.78      0.81      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PROHEutKfFCk"
   },
   "source": [
    "## 3. Logistic Regression using Scikit Learn Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_9Rw0fggIFN"
   },
   "source": [
    "### 3.1 Remove the bias vector which is used by previous method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ja1AudAKfeOM"
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:, 1:]\n",
    "X_test = X_test[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uV90IZcRgUBS"
   },
   "source": [
    "### 3.2 Train the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "pbZny5H9faY7",
    "outputId": "d06caf59-70b6-48e6-bdd6-de7fb478151f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdRg_p1zgiOb"
   },
   "source": [
    "### 3.3 Evaluate the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "bzPwVoVafsBP",
    "outputId": "3ef8ba5b-d62b-4c33-b5de-59e55f94cacc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1526   69]\n",
      " [ 309   96]]\n",
      "\n",
      "Accuracy Score: 0.811\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      1595\n",
      "           1       0.58      0.24      0.34       405\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2000\n",
      "   macro avg       0.71      0.60      0.61      2000\n",
      "weighted avg       0.78      0.81      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGC09gtNhCr_"
   },
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "**The Logistic Regression build from scratch has the same results with the Scikit Learn Logistic Regression Model.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "logistic_regression_from_scratch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
